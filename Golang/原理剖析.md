## 程序初始化

> 简短, 结论就是那几个点

在Go语言中，如果一个文件包含多个`init`函数，这些函数的执行顺序遵循它们在代码中出现的顺序。即，先出现的`init`函数先执行

这意味着，在同一个文件内，`init`函数的执行顺序是确定的，并且是可以控制的。在不同文件之间，`init`函数的执行顺序则取决于文件的编译顺序，这通常是根据文件名的字典序确定的（但这并非是由语言规范所保证的，而是Go工具链的一个实现细节）。

## string

> 简单  一个指针 一个len保存字节长度

[Golang是值传递还是引用传递 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/542218435)   todo

[面试官：string和byte转换原理知道吗？会发生内存拷贝吗？ (zhihu.com)](https://www.zhihu.com/tardis/sogou/art/386676358)

> 我不太理解, 比如一个英文字母在string中对应一个字节, 一个中文汉字可能对应三个字节,  那我把一个字节数组转化为string, 它是如何知道接下来应该将一个字节解析为一个英文字母, 还是三个字节解析为一个中文汉字呢?
>
> ChatGPT
>
> 当你把一个字节数组转换为`string`时，Go语言并不会"知道"字节应该如何被解释——它只是简单地将这些字节作为字符串内容。在Go中，字符串是字节的序列，而解释这些字节意味着什么（即它们代表什么字符）是依赖于这些字节是如何被读取和处理的。
>
> 当字符串用作文本时，Go假设它是UTF-8编码的。UTF-8编码有一个特点，它是**自同步**的，这意味着你不需要任何额外的信息就能从任何字节位置确定字符边界。UTF-8编码使用以下规则：
>
> - 单个字节的值从0到127保留给标准ASCII字符集，匹配ASCII中的单个字符。
>- 多字节序列以一个非ASCII的单个字节开始（128到255），后跟一个或多个连续字节。第一个字节的高位位模式指示了序列中有多少字节。例如，如果第一个字节的前两位是`11`，则表示至少有一个后续字节。如果前三位是`110`，则表示有两个字节组成了一个字符，如果是`1110`，则表示有三个字节，以此类推。
> 
>这样，解码器只需要查看每个字节，就可以根据其值确定它是ASCII字符、多字节序列的开始，还是多字节序列中的一个后续字节。这就是Go如何知道应该将一个字节解析为一个英文字母还是三个字节解析为一个中文汉字。
> 
> 例如，当Go读取到一个字节序列时，如果第一个字节的值小于128，它知道这是一个单字节的ASCII字符；如果值大于或等于128，它将查看足够的后续字节来确定整个字符。
>
> 在处理文本时，很多Go标准库函数都假设字符串是UTF-8编码的，并会相应地处理它们。例如，`range`关键字在迭代字符串时会自动按UTF-8规则解码每个Unicode字符（称为rune）。如果字符串包含非UTF-8序列，这些函数可能无法正确解释内容，或者可能导致运行时错误。

## slice

> 简单, 真足够了, 够清晰了:)

切片slice的结构

slice扩容的第一阶段 ok

第二阶段 什么分级什么的, 直接过了

最后是mallocgc这个函数来分配内存

说实话, 除了扩容策略, 其它都随便讲了讲



后面讲了几个问题

问题一: 其实就是通过指针的转换探究slice的函数参数传递传递的是什么, 其实就是**三个元素的直接拷贝, 值传递** 

问题二: case2里面s扩容了:)

![image-20240329191810808](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329191810808.png)

![image-20240329191837192](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329191837192.png)

问题3

![image-20240329192127378](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192127378.png)

![image-20240329192145459](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192145459.png)

![image-20240329192213628](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192213628.png)

![image-20240329192240127](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192240127.png)

问题4 真不错!!!!!!!

![image-20240329192603075](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192603075.png)

![image-20240329192625215](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192625215.png)

问题5 

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192737112.png" alt="image-20240329192737112" style="zoom:150%;" />

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192831240.png" alt="image-20240329192831240" style="zoom:150%;" />

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192927218.png" alt="image-20240329192927218" style="zoom:150%;" />

shen kao

![image-20240329193130353](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329193130353.png)

最后一个题也不错, 还挺考验对slice的理解的

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329193322974.png" alt="image-20240329193322974" style="zoom: 67%;" />

slice的append扩容

append追加后返回的是一个新的切片, 注意这里的新的切片, 指的是新的切片结构体

- s3的append回覆盖s2的append的2

```Go
func test1() {
	s1 := make([]int, 0, 4)
	s1 = append(s1, 1)
	s2 := append(s1, 2)
	s3 := append(s1, 3)
	fmt.Printf("%v, address:%p, %p\n", s1, &s1, &s1[0])
	fmt.Printf("%v, address:%p, %p\n", s2, &s2, &s2[0])
	fmt.Printf("%v, address:%p, %p\n", s3, &s3, &s3[0])
	// s3的append对s2之前的append产生了覆盖, 底层都是一个数组
	//[1], address:0xc000008048, 0xc000014140
	//[1 3], address:0xc000008060, 0xc000014140
	//[1 3], address:0xc000008078, 0xc000014140
	s1[0] = 100
	fmt.Println(s1)
	fmt.Println(s2)
	fmt.Println(s3)
	//[100]
	//[100 3]
	//[100 3]

	//num := s1[1]
	//fmt.Println(num)
	// panic: runtime error: index out of range [1] with length 1
	s4 := append(s1, 2, 3, 4, 5) // 超过了容量4
	// 此时, s4因为append之后的数据完全超过了原始数组空间的容量
	// 所以在新的地方扩容
	fmt.Printf("%v, address:%p, %p\n", s1, &s1, &s1[0])
	fmt.Printf("%v, address:%p, %p\n", s2, &s2, &s2[0])
	fmt.Printf("%v, address:%p, %p\n", s3, &s3, &s3[0])
	fmt.Printf("%v, address:%p, %p\n", s4, &s4, &s4[0])
	//[100], address:0xc000094030, 0xc000092040
	//[100 3], address:0xc000094048, 0xc000092040
	//[100 3], address:0xc000094060, 0xc000092040
	//[100 2 3 4 5], address:0xc000094108, 0xc0000ac080
	fmt.Println(len(s1), cap(s1)) // 1 4
	fmt.Println(len(s2), cap(s2)) // 2 4
	fmt.Println(len(s3), cap(s3)) // 2 4
	fmt.Println(len(s4), cap(s4)) // 5 8  (可能是2倍扩容
}
```

比如上方的s4, append时, slice的容量不足怎么办?

![image-20231230180546896](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\slice.assets\image-20231230180546896.png)

![image-20231230180604236](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\slice.assets\image-20231230180604236.png)

若需要的容量大于现有的2倍, 直接扩到需要的容量

否则 看现有是否 < 256, 若小于, 则2倍扩容. 若>=256, 按照公式扩容, 直到满足需要为止

其实公式扩容就是, 防止2倍扩容太激进



再看一个

```Go
// 结合slice的底层结构来看
func Slice0() {
	arr := [3]int{1, 2, 3}
	sli := arr[1:2] // [2]  len:1 cap:2
	fmt.Printf("%p\n", sli)
	sli = append(sli, 4)
	fmt.Println(arr)        // [1 2 4]
	fmt.Println(sli)        // [2 4]
	fmt.Printf("%p\n", sli) // 没变, 因为没扩容
	sli[1] = 10
	fmt.Println(arr) // [1 2 10]
	fmt.Println(sli) // [2 10]
	sli = append(sli, 6)  // [2 10 6]  且是新的空间, 不是原数组了
	fmt.Printf("%p\n", sli) // 变了, 因为扩容了, 指向新的空间
	sli[1] = 8
	fmt.Println(arr) // 1 2 10  // 没变, 因为修改前, 切片已经指向新的地址了
	fmt.Println(sli) // 2 8 6

	//0xc000012140
	//[1 2 4]
	//[2 4]
	//0xc000012140
	//[1 2 10]
	//[2 10]
	//0xc000014180
	//[1 2 10]
	//[2 8 6]
}
```

从一个切片截取出另一个切片，修改新切片的值会影响原来的切片内容吗
在截取完之后，如果新切片没有触发扩容，则修改切片元素会影响原切片，如果触发了扩容则不会

## map

[深入解析Golang的map设计 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/273666774)

这个文章很不错

---

先初步看一下整体的结构, Golang的map采取的是变种拉链法, 和常规的拉链法有所不同

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230212039801.png" alt="image-20231230212039801" style="zoom:100%;" />

- Golang中的map实际上是一个指向hmap结构的指针. 核心就是由`hmap`和`bmap`两个结构体实现
- buckets  一个指针, 指向bmap数组, 其中包含2^B个标准桶, 溢出桶数量不定, 若map元素个数为0, 则buckets为nil (实际上标准桶和溢出桶都是在一整个bmap数组中连续存储的(如上图))
- `noverflow` 字段用于记录哈希表中溢出桶（overflow buckets）的数量。
- `oldbuckets`字段在非扩容时, 为nil, 扩容时, 指向旧的buckets数组(旧的bmap数组)
- 小于`nevacuate`的桶都已经迁移完成, navacuate是迁移的进度
- key的哈希值的低B位用于选择桶, 高8位用于在桶内部进行区分不同的key, bmap存的也是高八位

bmap结构 === 8tophash 8k 8v overflow     tophash 是键值对的键通过哈希因子计算出的哈希值的高8位

```Go
type bmap struct {
    topbits [8]uint8
    keys [8]keytype
    values [8]valuetype
    overflow uintptr
}
```

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230212344499.png" alt="image-20231230212344499" style="zoom:67%;" />

#### map初始化

```
// 初始化一个可容纳10个元素的map
info = make(map[string]string, 10)
```

- 第一步：创建一个hmap结构体对象。

- 第二步：生成一个哈希因子hash0 并赋值到hmap对象中（用于后续为key创建哈希值）。

- 第三步：根据hint=10，并根据算法规则来创建 B，当前B应该为1。

  ```
  hint            B
  0~8				0
  9~13            1
  14~26           2
  ...
  ```

- 第四步：根据B去创建去创建桶（bmap对象）并存放在buckets数组中，当前bmap的数量应为2.

  - 当B<4时，根据B创建桶的个数的规则为：2^B（标准桶）
  - 当B>=4时，根据B创建桶的个数的规则为：2^B + 2^(B−4)（标准桶+额外的溢出桶）

  这些桶都由buckets指向

  注意：每个bmap中可以存储8个键值对，当不够存储时需要使用溢出桶，并将当前bmap中的overflow字段指向溢出桶的位置。

![image-20231230215004266](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230215004266.png)

#### map的访问原理

意料之中

#### map的赋值原理

...todo

#### 扩容

在向map中添加数据时，当达到某个条件，则会引发字典扩容。

扩容条件：

- map中数据总个数 / 桶个数(负载因子) > 6.5 ，引发**翻倍扩容**。
- 使用了太多的溢出桶时（溢出桶使用的太多会导致map处理速度降低）。
  - B <=15，已使用的溢出桶个数 >= 2^B 时，引发**等量扩容**。
  - B > 15，已使用的溢出桶个数 >= 2^15 时，引发**等量扩容**。

> 为什么负载因子是6.5 ===

> 溢出桶数量过多的影响 ===

> 渐进式扩容 ===

扩容的基本流程:

- 第一步：更新B（翻倍扩容新B=旧B+1，等量扩容 新B=旧B）。
- 第二步：oldbuckets指向原来的桶（旧桶）。
- 第三步：buckets指向新创建的桶（新桶中暂时还没有数据）。
- 第四步：n evacuate设置为0，表示如果数据迁移的话，应该从原桶（旧桶）中的第0个位置开始迁移。
- 第五步：n overflow设置为0，扩容后新桶中已使用的溢出桶为0。
- 第六步：extra.oldoverflow设置为原桶（旧桶）已使用的所有溢出桶的地址数组。即：`h.extra.oldoverflow = h.extra.overflow`
- 第七步：extra.overflow(已经使用的溢出桶的数组)设置为nil，因为新桶中还未使用溢出桶。
- 第八步：extra.nextOverflow(下一个空闲的溢出桶)设置为新创建的桶中的第一个溢出桶的位置。
  (结合下方示意图)

![image-20231230212032802](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230212032802.png)

#### 迁移

扩容之后，必然要伴随着数据的迁移，即：将旧桶中的数据要迁移到新桶中。

##### 翻倍扩容

如果是翻倍扩容，那么迁移规则就是将旧桶中的数据分流至新的两个桶中（比例不定），并且桶编号的位置为：同编号位置 和 翻倍后对应编号位置。

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230220942783.png" alt="image-20231230220942783" style="zoom: 50%;" />

如何实现的这种迁移呢？

> 首先，我们要知道如果翻倍扩容（数据总个数 / 桶个数 > 6.5），则新桶个数是旧桶的2倍，即：map中的B的值要+1（因为桶的个数等于2^B，而翻倍之后新桶的个数就是2^B * 2 ，也就是2^{B+1}，所以 `新桶的B的值=原桶B + 1` ）。

迁移时会遍历某个旧桶中所有的key（包括溢出桶），并根据key重新生成哈希值，根据哈希值的 `底B位` 来决定将此键值对分流道那个新桶中。(B已经变了)

![image-20231230222511586](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230222511586.png)

扩容后，B的值在原来的基础上已加1，也就意味着通过多1位来计算此键值对要分流到新桶的位置，如上图：

- 当新增的位（红色）的值为 0，则数据会迁移到与旧桶编号一致的位置。
- 当新增的位（红色）的值为 1，则数据会迁移到翻倍后对应编号位置。

例如：

```
旧桶个数为32个，翻倍后新桶的个数为64。
在重新计算旧桶中的所有key哈希值时，红色位只能是0或1，所以桶中的所有数据的后B位只能是以下两种情况：
	- 000111【7】，意味着要迁移到与旧桶编号一致的位置。
	- 100111【39】，意味着会迁移到翻倍后对应编号位置。
特别提醒：同一个桶中key的哈希值的低B位一定是相同的，不然不会放在同一个桶中，所以同一个桶中黄色标记的位都是相同的。
```

##### 等量扩容

如果是等量扩容（溢出桶太多引发的扩容），那么数据迁移机制就会比较简单，就是将旧桶（含溢出桶）中的值迁移到新桶中。

**这种扩容和迁移的意义在于：当溢出桶比较多而每个桶中的数据又不多时，可以通过等量扩容和迁移让数据更紧凑，从而减少溢出桶。**

比如当前buckets的0号下标有1个原桶, 3个溢出桶, 但是元素个数为2,3,4,2, 则通过等量扩容, 就会使得新的map的0号只需要1个原桶, 1个溢出桶

---

两个条件: 1. 不是正在扩容(避免二次扩容) 2. 负载因子6.5 或 太多的溢出桶  ===(源码)

两个核心方法: hashGrow(赋值操作时触发, 上面两个条件满足) growWork

渐进式扩容: 

hashGrow: 分配新的buckets, oldbuckets字段指向旧的bmap数组, 此时并没有进行数据迁移. 只是做了扩容的准备工作

growWork: 进行数据迁移, 迁移的时机: 插入, 修改, 删除时. 写时复制的方式

首先, 插入修改删除, 都是访问到某一个桶, growWork会先将访问的这个桶进行迁移, 再根据n evacuate标记的迁移进度, 再迁移一个. 所以, 每次growWork会迁移两个桶, 一个是当前访问的, 一个是nevacuate标记的迁移进度

这两个迁移, 都是依靠一个evacuate函数进行的:

1. 看当前这个buckets是否已经迁移(怎么判断????), 若已经迁移, 直接返回. 判断方法: 通过tophash中的第一个hash值, 判断当前桶是否已经迁移===
2. 计算目标桶的位置, 逐个迁移旧桶中的key/value
3. 迁移完一个桶之后, 旧将nevacuate+1, 若nevacuate等于旧桶的数组大小时, 代表迁移完成, 释放旧的桶数组
   +1操作不是每次都执行吧???

#### 写入数据

===

#### 读取数据

===

> 读写其实都有对应的源码, 我真的看了吗? 我真的需要看吗?   ===

#### 删除数据

删除操作前的逻辑和访问查找的逻辑差不多

核心: tophash标记位的 emptyOne emptyRest

emptyRest的作用: 这样做的目的是将emptyRest状态尽可能地向前面的槽推进，这样做是为了增加效率，因为在查找的时候发现了emptyRest状态就不用继续往后找了，因为后面没有元素了。

#### 遍历数据

每次遍历随机找一个桶的随机一个下标, 这次遍历的后面的桶时, 都是从这个对应下标开始的

通过迭代器实现

===





## sync.map

key同时存在, 然后删除, nil, 之后状态流转, dirty为nil, 此时, 在状态流转第二步之前, 如果key进行写, 你又没有及时地将其置为exp, 那怎么办?



- 三个状态: value就是 *entry entry有三个状态, 1. 存在正常 2. 存在物理内存中但逻辑删除(nil软删除, expunged硬删除)  那不存在就没有状态, 懂吗

好问题, 多思考: 这里我们可能会想，entry不就是key对应value吗?不就指向真正的物理内存就可以了，为什么还需要一个nil和expunged状态    But!当数据同时存在read map和dirty map中的时候，我们就可以想办法让read map来帮我们消耗删除流量，从而实现无锁删除，通过CAS操作将p的值变成nil，来标识当前key逻辑上已经被删除了(但是物理上，小林和诸葛青仍然有这个数据)   同时可以优化先删后写的场景

expunged这里也理解了, 也就是, 为了实现read map实现无锁删除, 引发出了问题, 那怎么解决? 就是expunged

·而设计expunged状态是为了正确标识出key-entry对是否存在于dirty map中  (在能咋, 不在能咋, 没有这个会引发什么问题?)



[不得不知道的Golang之sync.Map解读！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/528736727)

下面自己写的纯属小丑, 多看多理解上面这个, 才是正确的选择

nil expunged 这两个比较关键, 理解为什么要有expunged状态  过程缕一缕

Golang内置的map不支持并发读写能力, sync.Map: 并发安全的字典

---

两个map互相配合, 一个read map, 一个dirty map, 空间换时间的思想

read map类似于缓存层, dirty map类似于全量数据库

读 写 删除 更新



读删更新 先找read map, 若read map不支持对应kv的操作, 再找dirty map

写, 一定要找dirty map

sync.Map的结构  ===

读 删 更新对于read map来说, 无需加锁, 通过原子性(要么完成, 要么不完成, 并发安全)的CAS操作即可完成

操作dirty map, 无论是写, 还是read map渗透过来的其它操作, 都需加锁完成

misses 记录多少次读删找了dirty map, 注意, 这里没有更新操作.

amended 字段记录rmap和dmap是否有数据差异

---

写, 一定是写给dirty map, 那么, 随着写的次数增多, rmap dmap的数据差异就会增加, amended就会为true

那么, rmap dmap如何数据同步呢? 就是依靠双向数据流转机制

简单概括:

1. dmap将全量数据直接交给rmap(O(1))
2. rmap O(N)将数据拷贝给dmap

随着写操作增加, misses增加, dmap压力增加, 到了阈值, 就会引发操作1

给了rmap之后, dmap为nil, 没有数据

在此之后, 若有新的写发生, dmap为nil, 无法支持写操作, 此时需要初始化dmap

而这个初始化过程就是操作2, 将rmap中逻辑上存在的数据(kv)拷贝给dmap O(N)

> 逻辑存在, 逻辑不存在...:

----

双向数据流转机制:

dmap为什么要在操作1时, 将自己置为nil?

因为如果不这样, 则dmap rmap底层就是一个map, 而我们期望的是, 两者是不同的map, 只是value共享

dmap为什么不拷贝一份数据给rmap?

不能, 这属于写rmap, 这样在ON拷贝期间, sync.Map无法支持其它所有操作

---

entry:

rmap dmap都是map, value的类型是*entry类型

entry是一个结构体, 数据成员是一个指针, 类似于C++的void*

entry三个状态:

1. nil - 软删除态, 逻辑不存在, 物理存在 - rmap dmap的key 都指向这个value, 只是value是一个nil
2. expunged - 硬删除态 - rmap的key存在, 指向这个expunged的value, 而dmap没有这个key!
3. 正常值

12 : 都是逻辑删除态, 逻辑删除代表着逻辑上是没有的, 我们访问这个key时, key不存在, 而物理上是存在的
区别在于, nil是rdmap都有这个key, expunged是rdmap中只有read map有key

---

区分这三个状态的作用是什么?

read map帮助dirty map消除了读 删 更新的压力

删 - 当key value同时存在于两个map时, 若想让删除直接在read map中完成, 并且是无锁原子操作, 则直接将value变成nil即可

这就是逻辑上已经不存在了(物理上, kv依旧存在)

此后, 读: nil逻辑不存在, 符合要求, 读不到   写: read map 直接将nil改为对应的value即可, 此时无需加锁访问dirty map



nil - 应用于对一个key 先删后写 的场景, 这个过程无需加锁访问dirty map



----

expunged

双向数据流转的操作2: readmap 将逻辑存在的kv 以O(N)拷贝给dirty map

此时nil不会拷贝给dmap, 那么, 下一次写的时候, 如果按照上方所述的直接写在read map中, 就错误了, 因为此时dmap就会丢失这个kv

所以要加一个状态, expunged, 表示具体对这个逻辑上删除的key value, rmap dmap是否同时存储

若rmap dmap都有这个逻辑不存在的kv, 就是nil, 下次写这个key时, 直接rmap就可以完成

若rmap有, dmap没有, 则就是expunged, 表示rdmap没有共享这个逻辑不存在的key

此时, 写这个key, 就需要加锁写在dmap中!!! 写完之后, rd map就同时存储这个kv了



---

entry的三种状态的总结:

正常值不说了

不管是nil状态还是expunged状态，都代表逻辑上，key-entry从 sync.Map中已经删除了
nil状态:我们将其称之为软删除，但是read map和dirty map中物理上仍有这个key-entry对，**同时我们可以基于CAS操作来让read map消耗对p为nil的key-entry进行写的流量(优化对同一个key先删后写的场景)**
expunged状态:我们将其称之为硬删除，物理上dirty map中已经没有key-entry对，它能帮助我们标识出dirtymap当前有没有这个逻辑删除的key-entry(如果dirty map没有，我们就需要访问dirty map)

总结其实就是, nil可以优化一种写的场景, 即先删后写. 但是如果没有expunged, 就是有问题的, 所以加了一个expunged状态

---

整体: 

核心就是, read map 和 dirty map他们是共享value的

所以对于共享的key value, 读, 更新, 删, 都可以在readmap上以原子性操作, 并发安全地完成, 这是很大的进步

而新的key, 是写在dirty map中的, 随着写的增多, 数据差异增大, 有些读 删 更新, readmap 无法完成

misses字段记录多少次读 删找了dirty map, 随着misses到了阈值, dmap就会进行数据同步, 给rmap

先直接把全量数据交给rmap, 之后, 读删更新都行, 但是写找dmap时, 还需要数据流转第二步, 将数据拷贝给dmap, 且是逻辑存在的

而在1和2之间, 也就是rmap有全量, dmap为nil时: 读, 更新都无所谓, 而删, 可以把value置为nil

当进行第二步时, 会将value改为expunged, 表示dmap没有这个key

----

核心:

数据流转第二步:

若kv正常, 则拷贝, 若value为nil, 则置为expunged, 不拷贝

读:

读read map, 不存在 && amended 则, 加锁, 二次检查readmap(是因为这个加锁操作可能被阻塞了, 拿到锁时, 其它goroutine完成了数据流转的第一步), 若还是没, 就去dirty map查, misses+1 解锁

若misses到了diry map存储的kv数量, 就是到达了阈值, 就进行数据流转第一步, dmap给rmap dmap重置为nil, misses重置为0



写: (包含更新)

查readmap 有没有, 若有, 就是更新. 此时直接更新rmap即可, 这就是rmap的作用嘛  (1. rdmap都有kv, 正好 2. rmap有kv, dmap为nil, 无妨, 后续的数据流转会再拷贝给dmap的)
此时还要看v的状态, 若为expunged, 则代表dmap没有key, 此时直接返回, 不能更新, 否则dmap会丢失
若正常值, 或者nil(先删后写), 直接更新即可

若没结束, 说明rmap没有, 或者有, 为expunged状态, 就去dmap找

加锁, double check 一下rmap, 若第二次有了, nil或者正常, 就直接更新, expunged, 则更新value, 且在dmap中写一下对应的key(有点绕)

如果rmap没有, 就找dmap

若两者都没, 那么就是写喽
先看是不是rmap和dmap没有数据差异(amended), 如果没有数据差异
进一步判断, 若dmap为nil, **就要进行数据流转的第二步了**, 加锁, 将所有逻辑存在的kv给dmap, 此时每个kv都要判断v的状态, 若是nil, 就要改为expunged状态正确标识出, 这个流转完之后, dmap是没有对应的key的, 也就是expunged  这里其实就是数据流转第二步. 
此后, 还是没有数据差异的逻辑, 更新一下, 有数据差异了, 写给dmap, 解锁

删除:

看readmap有没有, 没有, 且数据缺失, 加锁, doublecheck, 如果readmap有, 就是逻辑删除, 没有就查dirty map, 物理删除, misses+1

如果readmap有, 就进行逻辑删除,  如果已经是nil或者expunged, 就不需要进行第二次逻辑删除  ,而如果是正常value ,就置为nil, 表示逻辑删除

确实misses只记录读+删, 写(更新)不会+misses

遍历:

如果是遍历dmap就太不合适了, 因为是加锁访问

所以, 先看有没有数据缺失, 如果有, 就进行数据流转第一步

无锁读rmap



**其实 nil本身支持了删操作不访问dmap, 只访问rmap, 而顺便支持了先删后写**

第一个才是核心目标, 真正的目的



----------

捋一下整个流程:

kv有几种情况

1. 正常, k在两个map中都有, v正常
2. v为nil, 代表的含义是两个map都有这个key(实际上可能和实际不符)
3. v为expunged, 表示dirty map没有这个key, 只有read map有key
4. key在read map不存在, 去找dirty map





目标: 把读, 删, 更新的操作尽量的在read map完成

对于情况1的key, 读, 可以, 删, 置为nil, 可以, 更新, 可以

而写必须在dirty map加锁完成

随着写增多, 后续, 如果某个kv只在dirty map存在, 则读, 删, 更新都必须在dirty map完成 (读, 读即可, 更新, 没问题, 删? 初步认为是置为nil)

而misses记录读删发生在dirty map的次数



而数据流转第一步之后, 其实此时的read map就是之前的dirty map, 全量数据, 除了写, 都没问题. 删, 也是置为nil

而一旦写发生, 就要数据流转第二步   O(N), 要把逻辑存在的拷贝给dirty map

如果是nil的, 就置为expunged, 否则, 如果也拷贝过去, 之后的先删后写的nil优化就有问题了





----

面试与分析......  todo

初始状态: dmap和rmap的状态并非完全一致

## channel

> channel这块的代码清晰, 也好理解
>
> 写入时, 若有读等待goroutine, 则直接写给这个读等待g, 并唤醒它. 那么为什么这样呢? 因为只要是有读等待goroutine, 则意味着环形数组要么为空, 要么无缓冲, 所以直接写给这个读等待的g即可
>
> 而读取时, 若有写等待goroutine, 不能直接读取写等待g的待写入元素, 此时要判断环形数组是否为空, 若不为空, 则读取环形数组的元素, 并把写等待g的待写入元素写入到环形数组中, 为什么呢? 因为数组的元素先于写等待g的待写入元素, 先进先出.  若环形数组为空, 也就是无缓冲, 则直接读取写等待g的元素即可

然后要注意channel是直接分配到堆上的，因为channel从设计理念上看，就是用于goroutine之间的通信，作用域和生命周期不会被限制在一个函数中

- Channel数据结构

这里很清楚易懂: qcount已有元素个数 datasize容量 sendx recvx 两个等待队列 一把锁

sudog是对挂起的goroutine的一个封装

- Channel初始化 - 文档

- 向Channel中写入数据

runtime.chansend 函数

五种case

case1: channel中有读等待的goroutine  重点是理解, 将要写入的数据如何拷贝到读等待的goroutine的待接收元素中

```
ch <- a   // a就是ep
b <- ch    // 读等待的goroutine, 封装为了sudog
```

步骤: 加锁, 复制元素, 解锁, 唤醒读等待的goroutine - goready方法: 先修改goroutine的状态, 再将goroutine放入GMP模型中

case2: 没有等待读的goroutine, 环形数组有剩余空间

加锁, 判断channel的环形数组中是否有空间, 若有, 根据sendx获取写入位置, ep中元素进行写入, sendx++, qcount++(环形数组元素个数), 解锁

case 3: 没有读等待goroutine, 没有剩余空间: 此时就是要把goroutine挂起嘛  此处就需要写等待队列了

获取一个sudog结构, 绑定channel, 绑定goroutine, 重点是待写入元素的地址要存入sudog.elem(unsafe.pointer)里面

把sudog加入到写等待队列中(hchan的sendq中), 再把这个goroutine挂起(涉及GMP)

case 4: 写入channel为nil

调用gopark挂起goroutine, 且不放入写等待队列中, 相当于goroutine永久坐牢

两种情况: 一个普通goroutine, 一种main goroutine(导致程序退出)

case 5: channel已关闭:  panic

- 从Channel中读取数据

```
a <- ch    // 也就是ep
```

case1 : Channel中有写等待goroutine

此时分两种情况: Channel无缓冲, Channel有缓冲但是满了

若无缓冲, 也就是, hchan.datasize == 0, 则把sudog中的数据, 写入到ep中

若有缓冲, 则获取recvx读取下标处的元素qp, 写入到ep中(其实就是从channel中读取走一个元素), 再将sudog中的待写入元素写入到recvx中(再写入一个元素到Channel中), recvx++, 唤醒对应的写等待goroutine

> 为什么这里不直接从写等待goroutine中取呢? 因为, channel是先进先出的, buf中的元素比写等待的goroutine更先写入, 也就更优先被读取走

case2: 没有写等待goroutine, 但是环形数组中有剩余待读取元素

非常合理的逻辑: 将hchan的recvx下标处的元素读取出到ep中

case3: 无写等待goroutine, 且环形数组无剩余待读取元素, 也就是要生成读等待goroutine

创建sudog, 重点: `mysg.elem = ep`, 也就是未来读取出元素要写入到哪里呢? 就是sudog.elem中, 将此sudog加入到hchan的recvq读等待队列中, gopark挂起当前goroutine

case4: nil  永久挂起goroutine, 若是main goroutine则报死锁错误程序退出	

case5: channel关闭了

已经关闭

若没有可读的了, 清空ep(读取出对应类型零值)

若有可读的接着读(meishuo)

- Channel关闭 close(ch) 

若Channel为nil: panic

二次关闭? panic

置c.closed = 1表示通道关闭, goready唤醒所有的等待读写的goroutine(sudog)

> channel接发数据的本质: 值的拷贝, ep指针写入时就是待写入元素地址, 读取时就是读取出的元素待被写入的地址. 还有就是sudog的elem, 读等待时就是待读取出元素写入的地址, 写等待时就是待写入的元素的地址

> 其实核心就是一个环形缓冲区, 两个队列嘛, 就像生产者消费者模型里面的交易场所一样, 只是生产消费里面的goroutine在交易场所不符合条件时, 会被阻塞, 其实就是调用某个系统接口, 被阻塞嘛, 这里其实也是一样, goroutine在条件不允许时, 被阻塞挂起, 然后组织进队列中, 方便后续条件就绪了唤醒以及其它操作

## select

实现原理:(无源码)

select分为阻塞(无default分支)和非阻塞(有default分支)

关键: 若阻塞型select且没有可执行的case, 则将执行select的goroutine加入到所有case的等待队列中, 比如case : a <- ch1, 则生成sudog绑定ch1, 当前goroutine, 加入到ch1的读等待队列中, 并挂起当前goroutine

后续若比如ch1有goroutine写入, 则就会将当前goroutine从所有的case对应channel的等待队列中移除

> 所以这里还是sudog, hchan的等待队列那些. 因为select是为channel服务的

具体挂起goroutine用gopark, 唤醒goroutine用goready



对nil的channel进行读和写都会造成当前goroutine永久阻塞（(如果当前goroutine是main goroutine，则会让整个程序直接报fatal error 退出)，关闭则会发生panic**(但这里我们不要忘记，还有一种叫做非阻塞的方式读写channel, 这种模式下，就算对为nil的channel读写，也不会阻塞的)** 指的是配合select的default分支

**后面两个示例**

## Context

#### Context基本使用

> > 基本使用上很简单, 要结合实际使用才能更好理解
>
> [Go标准库Context | 李文周的博客 (liwenzhou.com)](https://www.liwenzhou.com/posts/Go/context/)
>
> context.Context是一个接口  规定了四个函数(很简单), Deadline就是返回一个时间而已, Done返回一个channel, 只有在context被关闭的时候才会返回, 且是只读的.(其实这里被关闭的原因就有很多种可能了, 比如cancel被调用, 时间到了, 或者父context被关闭, 父被关闭又有多种可能, 比如cancel被调用, 时间到了, 或者父的父context被关闭)  Err就是返回一个关闭的原因而已 Value就是配合key value功能, 以及WithValue函数
>
> 两个生成顶层context对象的两个函数：`Background()`和`TODO()`，这两个函数分别返回一个实现了`Context`接口的`background`和`todo`。我们代码中最开始都是以这两个内置的上下文对象作为最顶层的`partent context`，衍生出更多的子上下文对象。
>
> WithCancel 返回一个带有新Done通道的子context, 什么时候子context的Done通道被关闭呢? 调用返回的cancel或者父context的Done通道被关闭. 无论先发生什么情况。
>
> WithDeadline 返回一个子context  当截止日过期时, 或当调用返回的cancel函数时，或当父上下文的Done通道关闭时，子上下文的Done通道将被关闭，以最先发生的情况为准.
>
> WithTimeout和上面的Deadline道理一样, 格式略有不同而已
>
> WithValue 挺简单, 但是类型这里没有看懂... 说的什么勾八

#### Context的作用和功能以及应用场景

!!!...

#### Context的实现

两个接口Context canceler 四种类型实现 : emptyCtx cancelCtx timerCtx valueCtx

> 四种类型都实现了Context, 若实现了canceler则具有调用cancel方法即可关闭context的功能, 有cancelCtx timerCtx两个类型实现了
>
> 如果只实现了Context, 没有实现canceler, 则不可以调用cancel方法进行取消, 比如emptyCtx和valueCtx

- Context interface  ...

- canceler interface  ...

- emptyCtx   

没任何功能, 唯一作用: 作为根Context, 用一系列with函数派生出新的Context    实现...

> Background TODO方法返回一个实现了Context接口的对象emptyCtx, 一般用于顶层context使用(context树的根节点)

看文档吧很简单, `type emptyCtx int`

- cancelCtx

cancelCtx : WithCancel返回的context实现对象实际上就是这个类型的对象

- timerCtx

timerCtx : 可以说是对于cancelCtx的一个扩展了, cancelCtx没有最终时间, 只能调用方法, 而这里还可以定过期时间

结构体, **内部一个cancelCtx**, 一个*time.Timer 一个time.Time

所以它拥有cancelCtx的全部功能 + 自己实现了canceler接口

WithTimeout  WithDeadline 都是返回的timerCtx类型

- valueCtx

valueCtx : 不是用于父子context之间取消的, 而是用于数据共享, 用于goroutine之间的数据传递

```
type valueCtx interface {
	Context
	key, val interface{}
}
```

`func (c *valueCtx) value(key interface{}) interface{}`  方法的实现: 向上递归查找key对应的value

> 也就是说, 每次调用WithValue时传入一个父context即可获取一个子类型为valueCtx的Context, 每个valueCtx只能存储一个kv且是有父子关系的
>
> 其实每个With系列的函数, 都是用于创建子Context的, 都是有父子关系的

WithValue的实现, 最终返回一个valueCtx

## defer

> 粗略, 可扩展

- defer是什么

关键字, 可修饰函数, 延迟到当前所在函数return或者panic的时候执行

- defer使用形式

函数名和参数都确定, 从当前函数退出时才执行

- defer底层结构

生成_defer结构体, 组织成一个\_defer链表, 当前goroutine的\_defer指向这个链表的头结点

type _defer struct {}

创建_defer结构后头插到goroutine的\_defer链表的头部, 这个存储结构很关键, 使得defer注册的函数是先注册的后执行

- defer执行过程

三种实现方式: 堆上分配内存 - runtime.deferproc, 栈上分配内存 - runtime.deferprocStack, 开放编码(内联) - 函数末尾直接对defer函数进行调用, 减少了函数调用的开销

性能由低到高, 优先使用高性能

- defer函数执行

函数退出时(return / panic), deferreturn()来遍历执行defer链表中的各个defer函数

## interface

> 可扩展    itab _type  eface iface

核心: 一个接口可以被多个类型实现, 一个类型可以实现多个接口, 所以有了itabTable

- 空接口interface{}

空接口即 eface 结构体

```Go
type eface struct {
    _type *_type    // 动态类型元数据
    data unsafe.Pointer  // 指向变量的指针, 动态值
}
```

- _type是什么

> 结构体, Golang中所有类型的一个抽象, 决定了data如何解释和操作, 几乎所有数据结构都可以抽象为_type

- 非空接口

> 包含方法列表的接口即非空接口, 实现上与空接口略有不同

```Go
type iface struct {
    tab *itab      // ..
    data unsafe.Pointer   // 指针指向接口的动态值
}
```

itab 结构存储了 **接口要求的方法列表** 以及 **动态类型信息**    (一个接口和一个类型实现即可确定唯一的一个itab结构)

type itab struct {}  ...

> 好理解, 有示例

- itab缓存

每个非空interface接口和具体类型, 就可以确定一个itab, 而不管具体类型的对象怎么变, itab不变

- itabTable

itabTable缓存所有的itab结构, 是一个数组(哈希表), 下标是接口类型与实际类型分别哈希之后的哈希值的异或值, 对应的值就是*itab, 指向itab结构体

GMP

https://www.bilibili.com/video/BV19r4y1w7Nx/?spm_id_from=333.337.search-card.all.click

看完了, 快速看也可以, 只看内容不听文字也可以吧

p2 历史  p3 GMP模型简介 p4 调度器的设计策略 p5 go func()执行流程 p6 M0 G0  p9-p17 一些场景



除了最后的源码部分, 大部分和视频是匹配的, 只是有些细节不太一样, 再看看其它文章吧



## Go语言垃圾回收

- 什么是GC garbage collection

> 为什么要有GC? 提升程序开发效率, 减少很多不必要的错误
>
> Java Go Python 都有GC, 而C, C++没有

- 常见的GC算法





标记清除算法

回收写冲突   todo

三色标记算法

为了解决标记清除的stop the world, 

白 灰 黑

白色: 起初都是白色  回收结束时, 所有白色代表不可达, 会被回收

灰色: 活跃的, 该对象不能回收, 但是存在指向白色对象的外部指针, 需要继续扫描其子对象

黑色: 活跃的, 该对象不能回收, 且所有字段都已被扫描, 不存在指向白色对象的指针



不就是一样的吗, 扫描完时, 能到的就是黑色, 到不了的就是白色, 只是说在扫描过程中, 有一个灰色状态, 灰色表示这个对象引申的对象还没有扫描, 它即将成为黑色



首先分析没有STW的三色标记法存在的问题

发生问题的两个条件

黑色引用白色 (破坏了原本的黑色的定义)

灰色到达白色的还没有扫描的路径被破坏了



12同时发生, 也就是原本的路没了, 加了一个不会扫描的路, 这个白色就被错误的回收了

或者1单独存在, 2根本没有, 也就是没有路被破坏, 而是突然加了一个不会扫描的路, 也会错误回收

总之结果一定是, 白色被黑色引用, 白色被错误回收



屏障技术

强三色不变性, 弱三色不变性

现在就是STW会影响性能, 但是不用STW又有问题, 怎么办?

需要破坏两个条件

黑色不会指向白色

黑色可以指向白色, 只是必须由灰色可达(也就是未来还是会把这个白色变为黑色, 最终结果也是黑色不会指向白色, 只是这个指的是过程中)



如果存在强的情况下, 弱只要想发生, 就一定会出现黑创建指向白的指针, 这样如果有强, 这个白就会变为灰啊



屏障技术

并发或增量标记 todo   屏障技术 保证 三色不变性   没听懂...    核心就是插入写屏障  删除写屏障

插入写屏障

其实很简单, 当A引用B时, 把B变为灰(记住, 灰色是会变为黑色的), 如果一个黑引用了白, 那么白变为灰, 就可以保证强三色不不变性了



只有堆开启了插入写屏障

也就是, 堆上的黑色对象突然创建一个引用, 引用白色对象因为有插入写屏障, 所以没有问题, 而栈没有开启, 也就是可能出现黑色引用白色, 解决方法是, 开启STW, 直到栈空间的三色标记结束



删除写屏障

灰引用白, 也就是还没有扫描, 那么, 删除这个引用关系时, 将被删除的标记为灰色(将来是不被删除的)

其实就是说, 被删除的一定要灰化处理, 特别针对白色的情况



优点 : 如果一个灰引用白, 这个引用被删除, 同时这个白又被其它的黑引用, 则不会出现问题, 因为引用被删除, 则这个白对象自动变为灰色

缺点: 可能某个白色确实被所有对象解除引用了, 但是还是变为了灰色, 也就是这一轮没有成功被回收, 需要到下一轮~



混合写屏障



在Golang（Go语言）的垃圾回收（GC）机制中，"三色标记法"是一个用于追踪和回收无用内存的算法。这个算法在内存管理中非常重要，尤其是在自动垃圾回收的语言中，如Go。三色标记法的核心概念涉及将对象标记为三种颜色之一：白色、灰色、黑色。这些颜色用于表示对象的访问和处理状态。

1. **白色：** 这种颜色代表尚未被访问的对象。在算法开始时，所有对象都被标记为白色。
2. **灰色：** 这种颜色表示对象已被访问，但其引用的对象尚未全部访问。灰色对象可能还包含对其他白色对象的引用。
3. **黑色：** 这种颜色表示对象已被访问，并且所有引用的对象也都已被访问。黑色对象不会引用任何白色对象。

垃圾回收过程通常包括以下步骤：

- **初始标记：** 标记所有从根对象（如全局变量、活动线程的栈帧等）直接可达的对象。这些对象被标记为灰色。
- **标记阶段：** 在这个阶段，灰色对象被检查，并将它们引用的所有白色对象标记为灰色。一旦一个灰色对象的所有引用都被检查过，它就会变成黑色。这个过程持续进行，直到没有更多的灰色对象。
- **清扫阶段：** 在所有的对象都被检查过后（即没有灰色对象），所有仍然是白色的对象被认为是不可达的，因此可以安全地回收。

Go语言的垃圾回收器使用了三色标记法的变体，并结合了并发执行和写屏障技术，以减少垃圾回收对程序性能的影响。通过并发运行垃圾回收过程，并使用写屏障来维护对象颜色的正确性，Go的垃圾回收器既能高效地回收内存，又能最小化对程序运行的干扰。

