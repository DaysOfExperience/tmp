# 程序初始化

> ez, 1min  就是文中的那几个点

在Go语言中，如果一个文件包含多个`init`函数，这些函数的执行顺序遵循它们在代码中出现的顺序。即，先出现的`init`函数先执行

这意味着，在同一个文件内，`init`函数的执行顺序是确定的，并且是可以控制的。在不同文件之间，`init`函数的执行顺序则取决于文件的编译顺序，<u>这通常是根据文件名的字典序确定的</u>（但这并非是由语言规范所保证的，而是Go工具链的一个实现细节）。

# string

> ez, 3min, 你要是真的急的话, 也就一个结构体两个字段嘛
>
> 其余不知道讲的什么, 其实就是俩字段罢了   

[Golang是值传递还是引用传递 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/542218435)   todo

[面试官：string和byte转换原理知道吗？会发生内存拷贝吗？ (zhihu.com)](https://www.zhihu.com/tardis/sogou/art/386676358)

> 我不太理解, 比如一个英文字母在string中对应一个字节, 一个中文汉字可能对应三个字节,  那我把一个字节数组转化为string, 它是如何知道接下来应该将一个字节解析为一个英文字母, 还是三个字节解析为一个中文汉字呢?
>
> 
>
> ChatGPT
>
> ChatGPT
>
> 当你把一个字节数组转换为`string`时，Go语言并不会"知道"字节应该如何被解释——它只是简单地将这些字节作为字符串内容。在Go中，字符串是字节的序列，而解释这些字节意味着什么（即它们代表什么字符）是依赖于这些字节是如何被读取和处理的。
>
> 当字符串用作文本时，Go假设它是UTF-8编码的。UTF-8编码有一个特点，它是**自同步**的，这意味着你不需要任何额外的信息就能从任何字节位置确定字符边界。UTF-8编码使用以下规则：
>
> - 单个字节的值从0到127保留给标准ASCII字符集，匹配ASCII中的单个字符。
> - 多字节序列以一个非ASCII的单个字节开始（128到255），后跟一个或多个连续字节。第一个字节的高位位模式指示了序列中有多少字节。例如，如果第一个字节的前两位是`11`，则表示至少有一个后续字节。如果前三位是`110`，则表示有两个字节组成了一个字符，如果是`1110`，则表示有三个字节，以此类推。
>
> 这样，解码器只需要查看每个字节，就可以根据其值确定它是ASCII字符、多字节序列的开始，还是多字节序列中的一个后续字节。这就是Go如何知道应该将一个字节解析为一个英文字母还是三个字节解析为一个中文汉字。
>
> 例如，当Go读取到一个字节序列时，如果第一个字节的值小于128，它知道这是一个单字节的ASCII字符；如果值大于或等于128，它将查看足够的后续字节来确定整个字符。
>
> 在处理文本时，很多Go标准库函数都假设字符串是UTF-8编码的，并会相应地处理它们。例如，`range`关键字在迭代字符串时会自动按UTF-8规则解码每个Unicode字符（称为rune）。如果字符串包含非UTF-8序列，这些函数可能无法正确解释内容，或者可能导致运行时错误。

# slice

> 10min, 直接看文档就完事了, ez

切片slice的结构

slice扩容的第一阶段 ok

第二阶段 什么分级什么的, 直接过了

最后是mallocgc这个函数来分配内存

说实话, 除了扩容策略, 其它都随便讲了讲



后面讲了几个问题

问题一: 其实就是通过指针的转换探究slice的函数参数传递传递的是什么, 其实就是**三个元素的直接拷贝, 值传递** 

![image-20240329191502943](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析.assets\image-20240329191502943.png)

值传递

问题二: (问题二其实还挺好的)

![image-20240329191810808](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329191810808.png)

![image-20240329191837192](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329191837192.png)

问题3也不错

![image-20240329192127378](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192127378.png)

![image-20240329192145459](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192145459.png)

![image-20240329192213628](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192213628.png)

![image-20240329192240127](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192240127.png)



问题4 真不错!!!!!!!

![image-20240329192603075](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192603075.png)

![image-20240329192625215](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192625215.png)

问题5 

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192737112.png" alt="image-20240329192737112" style="zoom:150%;" />

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192831240.png" alt="image-20240329192831240" style="zoom:150%;" />

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329192927218.png" alt="image-20240329192927218" style="zoom:150%;" />

shen kao

![image-20240329193130353](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329193130353.png)

最后一个题也不错, 还挺考验对slice的理解的

![image-20240329193322974](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\3slice.assets\image-20240329193322974.png)



我不知道下面这是些什么东西







### slice的append扩容

append追加后返回的是一个新的切片, 注意这里的新的切片, 指的是新的切片结构体

- s3的append回覆盖s2的append的2

```Go
func test1() {
	s1 := make([]int, 0, 4)
	s1 = append(s1, 1)
	s2 := append(s1, 2)
	s3 := append(s1, 3)
	fmt.Printf("%v, address:%p, %p\n", s1, &s1, &s1[0])
	fmt.Printf("%v, address:%p, %p\n", s2, &s2, &s2[0])
	fmt.Printf("%v, address:%p, %p\n", s3, &s3, &s3[0])
	// s3的append对s2之前的append产生了覆盖, 底层都是一个数组
	//[1], address:0xc000008048, 0xc000014140
	//[1 3], address:0xc000008060, 0xc000014140
	//[1 3], address:0xc000008078, 0xc000014140
	s1[0] = 100
	fmt.Println(s1)
	fmt.Println(s2)
	fmt.Println(s3)
	//[100]
	//[100 3]
	//[100 3]

	//num := s1[1]
	//fmt.Println(num)
	// panic: runtime error: index out of range [1] with length 1
	s4 := append(s1, 2, 3, 4, 5) // 超过了容量4
	// 此时, s4因为append之后的数据完全超过了原始数组空间的容量
	// 所以在新的地方扩容
	fmt.Printf("%v, address:%p, %p\n", s1, &s1, &s1[0])
	fmt.Printf("%v, address:%p, %p\n", s2, &s2, &s2[0])
	fmt.Printf("%v, address:%p, %p\n", s3, &s3, &s3[0])
	fmt.Printf("%v, address:%p, %p\n", s4, &s4, &s4[0])
	//[100], address:0xc000094030, 0xc000092040
	//[100 3], address:0xc000094048, 0xc000092040
	//[100 3], address:0xc000094060, 0xc000092040
	//[100 2 3 4 5], address:0xc000094108, 0xc0000ac080
	fmt.Println(len(s1), cap(s1)) // 1 4
	fmt.Println(len(s2), cap(s2)) // 2 4
	fmt.Println(len(s3), cap(s3)) // 2 4
	fmt.Println(len(s4), cap(s4)) // 5 8  (可能是2倍扩容
}
```

比如上方的s4, append时, slice的容量不足怎么办?

![image-20231230180546896](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\slice.assets\image-20231230180546896.png)

![image-20231230180604236](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\slice.assets\image-20231230180604236.png)

若需要的容量大于现有的2倍, 直接扩到需要的容量

否则 看现有是否 < 256, 若小于, 则2倍扩容. 若>=256, 按照公式扩容, 直到满足需要为止

其实公式扩容就是, 防止2倍扩容太激进



再看一个

```Go
// 结合slice的底层结构来看
func Slice0() {
	arr := [3]int{1, 2, 3}
	sli := arr[1:2] // [2]  len:1 cap:2
	fmt.Printf("%p\n", sli)
	sli = append(sli, 4)
	fmt.Println(arr)        // [1 2 4]
	fmt.Println(sli)        // [2 4]
	fmt.Printf("%p\n", sli) // 没变, 因为没扩容
	sli[1] = 10
	fmt.Println(arr) // [1 2 10]
	fmt.Println(sli) // [2 10]
	sli = append(sli, 6)  // [2 10 6]  且是新的空间, 不是原数组了
	fmt.Printf("%p\n", sli) // 变了, 因为扩容了, 指向新的空间
	sli[1] = 8
	fmt.Println(arr) // 12 10  // 没变, 因为修改前, 切片已经指向新的地址了
	fmt.Println(sli) // 2 8 6

	//0xc000012140
	//[1 2 4]
	//[2 4]
	//0xc000012140
	//[1 2 10]
	//[2 10]
	//0xc000014180
	//[1 2 10]
	//[2 8 6]
}
```

![image-20231230181947085](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\slice.assets\image-20231230181947085.png)





# map

Golang的map采取的是变种拉链法, 和常规的拉链法有所不同

[深入解析Golang的map设计 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/273666774)

这个知乎的文章太NB了, 结合起来看

其实基本都了解了, 扩容的策略啥的, 如果想详细看看的话, 主要是知乎文章, 结合一下训练营就OK了

---

md看了, 结构明白了, 这个md只有扩容, fs的后面详细过程不想看

查的过程, 删的过程, 增的过程... 扩容的过程... todo

---

### Golang-map结构

先初步看一下整体的结构

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230212039801.png" alt="image-20231230212039801" style="zoom:100%;" />

- Golang中的map实际上是一个指向hmap的指针, hmap里面三个指针
- buckets  一个指针, 指向bmap数组, 2^B个标准桶, 溢出桶不定, 若map元素个数为0, 则buckets为nil
- 实际上标准桶和溢出桶都是在一整个bmap数组中连续存储的(如上图)
- 核心是由`hmap`和`bmap`两个结构体实现
- `noverflow` 字段用于记录哈希表中溢出桶（overflow buckets）的数量。
- `oldbuckets`字段在非扩容时, 为nil, 扩容时, 指向旧的buckets数组(旧的bmap数组)
- 小于`nevacuate`的桶都已经迁移完成, navacuate是迁移的进度
- 低B位用于选择桶, 高8位用于在桶内部进行区分不同的key bmap存的也是高八位

bmap结构 === 8tophash 8k 8v overflow

tophash 是键值对的键通过哈希因子计算出的哈希值的高8位

```Go
type bmap struct {
    topbits [8]uint8
    keys [8]keytype
    values [8]valuetype
    overflow uintptr
}
```

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230212344499.png" alt="image-20231230212344499" style="zoom:67%;" />

#### map初始化

```
// 初始化一个可容纳10个元素的map
info = make(map[string]string, 10)
```

- 第一步：创建一个hmap结构体对象。

- 第二步：生成一个哈希因子hash0 并赋值到hmap对象中（用于后续为key创建哈希值）。

- 第三步：根据hint=10，并根据算法规则来创建 B，当前B应该为1。

  ```
  hint            B
  0~8				0
  9~13            1
  14~26           2
  ...
  ```

- 第四步：根据B去创建去创建桶（bmap对象）并存放在buckets数组中，当前bmap的数量应为2.

  - 当B<4时，根据B创建桶的个数的规则为：2^B（标准桶）
  - 当B>=4时，根据B创建桶的个数的规则为：2^B + 2^(B−4)（标准桶+额外的溢出桶）

  这些桶都由buckets指向

  注意：每个bmap中可以存储8个键值对，当不够存储时需要使用溢出桶，并将当前bmap中的overflow字段指向溢出桶的位置。

![image-20231230215004266](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230215004266.png)

#### 扩容

在向map中添加数据时，当达到某个条件，则会引发字典扩容。

扩容条件：

- map中数据总个数 / 桶个数(负载因子) > 6.5 ，引发**翻倍扩容**。
- 使用了太多的溢出桶时（溢出桶使用的太多会导致map处理速度降低）。
  - B <=15，已使用的溢出桶个数 >= 2^B 时，引发**等量扩容**。
  - B > 15，已使用的溢出桶个数 >= 2^15 时，引发**等量扩容**。

> 为什么负载因子是6.5.. ===

> 溢出桶数量过多的影响 ===

> 渐进式扩容 ===

扩容的基本流程:

- 第一步：更新B（翻倍扩容新B=旧B+1，等量扩容 新B=旧B）。
- 第二步：oldbuckets指向原来的桶（旧桶）。
- 第三步：buckets指向新创建的桶（新桶中暂时还没有数据）。
- 第四步：n evacuate设置为0，表示如果数据迁移的话，应该从原桶（旧桶）中的第0个位置开始迁移。
- 第五步：n overflow设置为0，扩容后新桶中已使用的溢出桶为0。
- 第六步：extra.oldoverflow设置为原桶（旧桶）已使用的所有溢出桶的地址数组。即：`h.extra.oldoverflow = h.extra.overflow`
- 第七步：extra.overflow(已经使用的溢出桶的数组)设置为nil，因为新桶中还未使用溢出桶。
- 第八步：extra.nextOverflow(下一个空闲的溢出桶)设置为新创建的桶中的第一个溢出桶的位置。
  (结合下方示意图)

![image-20231230212032802](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230212032802.png)

#### 迁移

扩容之后，必然要伴随着数据的迁移，即：将旧桶中的数据要迁移到新桶中。

##### 翻倍扩容

如果是翻倍扩容，那么迁移规则就是将旧桶中的数据分流至新的两个桶中（比例不定），并且桶编号的位置为：同编号位置 和 翻倍后对应编号位置。

<img src="C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230220942783.png" alt="image-20231230220942783" style="zoom: 50%;" />

如何实现的这种迁移呢？

> 首先，我们要知道如果翻倍扩容（数据总个数 / 桶个数 > 6.5），则新桶个数是旧桶的2倍，即：map中的B的值要+1（因为桶的个数等于2^B，而翻倍之后新桶的个数就是2^B * 2 ，也就是2^{B+1}，所以 `新桶的B的值=原桶B + 1` ）。

迁移时会遍历某个旧桶中所有的key（包括溢出桶），并根据key重新生成哈希值，根据哈希值的 `底B位` 来决定将此键值对分流道那个新桶中。(B已经变了)

![image-20231230222511586](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\map.assets\image-20231230222511586.png)

扩容后，B的值在原来的基础上已加1，也就意味着通过多1位来计算此键值对要分流到新桶的位置，如上图：

- 当新增的位（红色）的值为 0，则数据会迁移到与旧桶编号一致的位置。
- 当新增的位（红色）的值为 1，则数据会迁移到翻倍后对应编号位置。

例如：

```
旧桶个数为32个，翻倍后新桶的个数为64。
在重新计算旧桶中的所有key哈希值时，红色位只能是0或1，所以桶中的所有数据的后B位只能是以下两种情况：
	- 000111【7】，意味着要迁移到与旧桶编号一致的位置。
	- 100111【39】，意味着会迁移到翻倍后对应编号位置。
特别提醒：同一个桶中key的哈希值的低B位一定是相同的，不然不会放在同一个桶中，所以同一个桶中黄色标记的位都是相同的。
```

##### 等量扩容

如果是等量扩容（溢出桶太多引发的扩容），那么数据迁移机制就会比较简单，就是将旧桶（含溢出桶）中的值迁移到新桶中。

**这种扩容和迁移的意义在于：当溢出桶比较多而每个桶中的数据又不多时，可以通过等量扩容和迁移让数据更紧凑，从而减少溢出桶。**

比如当前buckets的0号下标有1个原桶, 3个溢出桶, 但是元素个数为2,3,4,2, 则通过等量扩容, 就会使得新的map的0号只需要1个原桶, 1个溢出桶

---

两个条件: 1. 不是正在扩容(避免二次扩容) 2. 负载因子6.5 或 太多的溢出桶  ===(源码)

两个核心方法: hashGrow(赋值操作时触发, 上面两个条件满足) growWork

渐进式扩容: 

hashGrow: 分配新的buckets, oldbuckets字段指向旧的bmap数组, 此时并没有进行数据迁移. 只是做了扩容的准备工作

growWork: 进行数据迁移, 迁移的时机: 插入, 修改, 删除时. 写时复制的方式

首先, 插入修改删除, 都是访问到某一个桶, growWork会先将访问的这个桶进行迁移, 再根据n evacuate标记的迁移进度, 再迁移一个. 所以, 每次growWork会迁移两个桶, 一个是当前访问的, 一个是nevacuate标记的迁移进度

这两个迁移, 都是依靠一个evacuate函数进行的:

1. 看当前这个buckets是否已经迁移(怎么判断????), 若已经迁移, 直接返回. 判断方法: 通过tophash中的第一个hash值, 判断当前桶是否已经迁移===
2. 计算目标桶的位置, 逐个迁移旧桶中的key/value
3. 迁移完一个桶之后, 旧将nevacuate+1, 若nevacuate等于旧桶的数组大小时, 代表迁移完成, 释放旧的桶数组
   +1操作不是每次都执行吧???

#### 写入数据

===

#### 读取数据

===

> 读写其实都有对应的源码, 我真的看了吗? 我真的需要看吗?   ===

#### 删除数据

删除操作前的逻辑和访问查找的逻辑差不多

核心: tophash标记位的 emptyOne emptyRest

emptyRest的作用: 这样做的目的是将emptyRest状态尽可能地向前面的槽推进，这样做是为了增加效率，因为在查找的时候发现了emptyRest状态就不用继续往后找了，因为后面没有元素了。

#### 遍历数据

每次遍历随机找一个桶的随机一个下标, 这次遍历的后面的桶时, 都是从这个对应下标开始的

通过迭代器实现

===





# sync.map

key同时存在, 然后删除, nil, 之后状态流转, dirty为nil, 此时, 在状态流转第二步之前, 如果key进行写, 你又没有及时地将其置为exp, 那怎么办?



- 三个状态: value就是 *entry entry有三个状态, 1. 存在正常 2. 存在物理内存中但逻辑删除(nil软删除, expunged硬删除)  那不存在就没有状态, 懂吗

好问题, 多思考: 这里我们可能会想，entry不就是key对应value吗?不就指向真正的物理内存就可以了，为什么还需要一个nil和expunged状态    But!当数据同时存在read map和dirty map中的时候，我们就可以想办法让read map来帮我们消耗删除流量，从而实现无锁删除，通过CAS操作将p的值变成nil，来标识当前key逻辑上已经被删除了(但是物理上，小林和诸葛青仍然有这个数据)    
同时可以优化先删后写的场景

expunged这里也理解了, 也就是, 为了实现read map实现无锁删除, 引发出了问题, 那怎么解决? 就是expunged

·而设计expunged状态是为了正确标识出key-entry对是否存在于dirty map中  (在能咋, 不在能咋, 没有这个会引发什么问题?)



[不得不知道的Golang之sync.Map解读！ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/528736727)

下面自己写的纯属小丑, 多看多理解上面这个, 才是正确的选择

nil expunged 这两个比较关键, 理解为什么要有expunged状态  过程缕一缕

Golang内置的map不支持并发读写能力, sync.Map: 并发安全的字典

---

两个map互相配合, 一个read map, 一个dirty map, 空间换时间的思想

read map类似于缓存层, dirty map类似于全量数据库

读 写 删除 更新



读删更新 先找read map, 若read map不支持对应kv的操作, 再找dirty map

写, 一定要找dirty map

sync.Map的结构  ===

读 删 更新对于read map来说, 无需加锁, 通过原子性(要么完成, 要么不完成, 并发安全)的CAS操作即可完成

操作dirty map, 无论是写, 还是read map渗透过来的其它操作, 都需加锁完成

misses 记录多少次读删找了dirty map, 注意, 这里没有更新操作.

amended 字段记录rmap和dmap是否有数据差异

---

写, 一定是写给dirty map, 那么, 随着写的次数增多, rmap dmap的数据差异就会增加, amended就会为true

那么, rmap dmap如何数据同步呢? 就是依靠双向数据流转机制

简单概括:

1. dmap将全量数据直接交给rmap(O(1))
2. rmap O(N)将数据拷贝给dmap

随着写操作增加, misses增加, dmap压力增加, 到了阈值, 就会引发操作1

给了rmap之后, dmap为nil, 没有数据

在此之后, 若有新的写发生, dmap为nil, 无法支持写操作, 此时需要初始化dmap

而这个初始化过程就是操作2, 将rmap中逻辑上存在的数据(kv)拷贝给dmap O(N)

> 逻辑存在, 逻辑不存在...:

----

双向数据流转机制:

dmap为什么要在操作1时, 将自己置为nil?

因为如果不这样, 则dmap rmap底层就是一个map, 而我们期望的是, 两者是不同的map, 只是value共享

dmap为什么不拷贝一份数据给rmap?

不能, 这属于写rmap, 这样在ON拷贝期间, sync.Map无法支持其它所有操作

---

entry:

rmap dmap都是map, value的类型是*entry类型

entry是一个结构体, 数据成员是一个指针, 类似于C++的void*

entry三个状态:

1. nil - 软删除态, 逻辑不存在, 物理存在 - rmap dmap的key 都指向这个value, 只是value是一个nil
2. expunged - 硬删除态 - rmap的key存在, 指向这个expunged的value, 而dmap没有这个key!
3. 正常值

12 : 都是逻辑删除态, 逻辑删除代表着逻辑上是没有的, 我们访问这个key时, key不存在, 而物理上是存在的
区别在于, nil是rdmap都有这个key, expunged是rdmap中只有read map有key

---

区分这三个状态的作用是什么?

read map帮助dirty map消除了读 删 更新的压力

删 - 当key value同时存在于两个map时, 若想让删除直接在read map中完成, 并且是无锁原子操作, 则直接将value变成nil即可

这就是逻辑上已经不存在了(物理上, kv依旧存在)

此后, 读: nil逻辑不存在, 符合要求, 读不到   写: read map 直接将nil改为对应的value即可, 此时无需加锁访问dirty map



nil - 应用于对一个key 先删后写 的场景, 这个过程无需加锁访问dirty map



----

expunged

双向数据流转的操作2: readmap 将逻辑存在的kv 以O(N)拷贝给dirty map

此时nil不会拷贝给dmap, 那么, 下一次写的时候, 如果按照上方所述的直接写在read map中, 就错误了, 因为此时dmap就会丢失这个kv

所以要加一个状态, expunged, 表示具体对这个逻辑上删除的key value, rmap dmap是否同时存储

若rmap dmap都有这个逻辑不存在的kv, 就是nil, 下次写这个key时, 直接rmap就可以完成

若rmap有, dmap没有, 则就是expunged, 表示rdmap没有共享这个逻辑不存在的key

此时, 写这个key, 就需要加锁写在dmap中!!! 写完之后, rd map就同时存储这个kv了



---

entry的三种状态的总结:

正常值不说了

不管是nil状态还是expunged状态，都代表逻辑上，key-entry从 sync.Map中已经删除了
nil状态:我们将其称之为软删除，但是read map和dirty map中物理上仍有这个key-entry对，**同时我们可以基于CAS操作来让read map消耗对p为nil的key-entry进行写的流量(优化对同一个key先删后写的场景)**
expunged状态:我们将其称之为硬删除，物理上dirty map中已经没有key-entry对，它能帮助我们标识出dirtymap当前有没有这个逻辑删除的key-entry(如果dirty map没有，我们就需要访问dirty map)

总结其实就是, nil可以优化一种写的场景, 即先删后写. 但是如果没有expunged, 就是有问题的, 所以加了一个expunged状态

---









整体: 

核心就是, read map 和 dirty map他们是共享value的

所以对于共享的key value, 读, 更新, 删, 都可以在readmap上以原子性操作, 并发安全地完成, 这是很大的进步

而新的key, 是写在dirty map中的, 随着写的增多, 数据差异增大, 有些读 删 更新, readmap 无法完成

misses字段记录多少次读 删找了dirty map, 随着misses到了阈值, dmap就会进行数据同步, 给rmap

先直接把全量数据交给rmap, 之后, 读删更新都行, 但是写找dmap时, 还需要数据流转第二步, 将数据拷贝给dmap, 且是逻辑存在的

而在1和2之间, 也就是rmap有全量, dmap为nil时: 读, 更新都无所谓, 而删, 可以把value置为nil

当进行第二步时, 会将value改为expunged, 表示dmap没有这个key





----

核心:

数据流转第二步:

若kv正常, 则拷贝, 若value为nil, 则置为expunged, 不拷贝





读:

读read map, 不存在 && amended 则, 加锁, 二次检查readmap(是因为这个加锁操作可能被阻塞了, 拿到锁时, 其它goroutine完成了数据流转的第一步), 若还是没, 就去dirty map查, misses+1 解锁

若misses到了diry map存储的kv数量, 就是到达了阈值, 就进行数据流转第一步, dmap给rmap dmap重置为nil, misses重置为0



写: (包含更新)

查readmap 有没有, 若有, 就是更新. 此时直接更新rmap即可, 这就是rmap的作用嘛  (1. rdmap都有kv, 正好 2. rmap有kv, dmap为nil, 无妨, 后续的数据流转会再拷贝给dmap的)
此时还要看v的状态, 若为expunged, 则代表dmap没有key, 此时直接返回, 不能更新, 否则dmap会丢失
若正常值, 或者nil(先删后写), 直接更新即可

若没结束, 说明rmap没有, 或者有, 为expunged状态, 就去dmap找

加锁, double check 一下rmap, 若第二次有了, nil或者正常, 就直接更新, expunged, 则更新value, 且在dmap中写一下对应的key(有点绕)

如果rmap没有, 就找dmap

若两者都没, 那么就是写喽
先看是不是rmap和dmap没有数据差异(amended), 如果没有数据差异
进一步判断, 若dmap为nil, **就要进行数据流转的第二步了**, 加锁, 将所有逻辑存在的kv给dmap, 此时每个kv都要判断v的状态, 若是nil, 就要改为expunged状态正确标识出, 这个流转完之后, dmap是没有对应的key的, 也就是expunged  这里其实就是数据流转第二步. 
此后, 还是没有数据差异的逻辑, 更新一下, 有数据差异了, 写给dmap, 解锁





删除:

看readmap有没有, 没有, 且数据缺失, 加锁, doublecheck, 如果readmap有, 就是逻辑删除, 没有就查dirty map, 物理删除, misses+1

如果readmap有, 就进行逻辑删除,  如果已经是nil或者expunged, 就不需要进行第二次逻辑删除  ,而如果是正常value ,就置为nil, 表示逻辑删除

确实misses只记录读+删, 写(更新)不会+misses





遍历:

如果是遍历dmap就太不合适了, 因为是加锁访问

所以, 先看有没有数据缺失, 如果有, 就进行数据流转第一步

无锁读rmap







**其实 nil本身支持了删操作不访问dmap, 只访问rmap, 而顺便支持了先删后写**

第一个才是核心目标, 真正的目的







----------









捋一下整个流程:

kv有几种情况

1. 正常, k在两个map中都有, v正常
2. v为nil, 代表的含义是两个map都有这个key(实际上可能和实际不符)
3. v为expunged, 表示dirty map没有这个key, 只有read map有key
4. key在read map不存在, 去找dirty map





目标: 把读, 删, 更新的操作尽量的在read map完成

对于情况1的key, 读, 可以, 删, 置为nil, 可以, 更新, 可以

而写必须在dirty map加锁完成

随着写增多, 后续, 如果某个kv只在dirty map存在, 则读, 删, 更新都必须在dirty map完成 (读, 读即可, 更新, 没问题, 删? 初步认为是置为nil)

而misses记录读删发生在dirty map的次数



而数据流转第一步之后, 其实此时的read map就是之前的dirty map, 全量数据, 除了写, 都没问题. 删, 也是置为nil

而一旦写发生, 就要数据流转第二步   O(N), 要把逻辑存在的拷贝给dirty map

如果是nil的, 就置为expunged, 否则, 如果也拷贝过去, 之后的先删后写的nil优化就有问题了





----

面试与分析......  todo









初始状态: dmap和rmap的状态并非完全一致





# channel

> channel这块的代码清晰, 也好理解, 其实不看视频也ok, 大致逻辑也是合理的





channel

写源码:

1. 读等待队列中有goroutine
2. 没有阻塞的读goroutine, 但是缓冲区有剩余空间
3. 没有等待中的读goroutine, 且缓冲区没有剩余空间

两种特殊case

1. 写入的channel为nil, 永久挂起(区别于上方第三点)
2. channel已经关闭了, panic



channel一定在堆上

hchan结构  - channel的结构 ===

有几个有疑虑的: elemsize elemtype 不算很重要

recvq sendq是两个队列, 算是比较重要的, 组织被阻塞的goroutine

recvq ===

每个recvq / sendq组织若干个被阻塞的goroutine, 每个goroutine都用一个sudog来表示

sudog ===

sudog的elem字段, 在goroutine发送被阻塞时, 指向待发送元素

在goroutine接收被阻塞时, 指向待接收的元素

---

其实核心就是一个环形缓冲区, 两个队列嘛, 就像生产者消费者模型里面的交易场所一样, 只是生产消费里面的goroutine在交易场所不符合条件时, 会被阻塞, 其实就是调用某个系统接口, 被阻塞嘛, 这里其实也是一样, goroutine在条件不允许时, 被阻塞挂起, 然后组织进队列中, 方便后续条件就绪了唤醒以及其它操作



---

### channel初始化

ez, 看文档即可, 就是, 有指针和无指针也挺好理解, span nospan

makechan的函数



### channel发送

runtime.chansend 函数

五种case

case1: 有读等待的goroutine

将要发送的元素拷贝给等待接收的元素 释放锁 唤醒goroutine 

唤醒具体来说, 就是goready函数, 先修改状态, 再将goroutine放入GMP模型中

case2: 没有等待读的goroutine, 环形数组有剩余空间

如果环形数组中元素数量 < 数组容量

这个过程其实也很合理, 根据index获取位置, 元素拷贝进去, 然后元素数量++, 写入位置++, 环形处理一下, 解锁嘛

case 3: 没有读等待goroutine, 没有剩余空间    此时就是要把goroutine挂起嘛  此处就需要sendq了

===

goready唤醒, gopark挂起  这里具体gopark如何把当前goroutine挂起呢? 视频里简单说了一下, 文档没有, 设计GMP

case 4:   写入channel为nil

只调用gopark挂起, 但是不放入队列中, 相当于永久坐牢

两种: 一个普通goroutine, 一种main goroutine

case 5: 已关闭

解锁, panic





读取: chanrecv函数

case1 : 有写等待goroutine

略有不同, 此时buf要么满, 要么无缓冲

从recv index指向的数据复制到ep指针中(其实就是从buf中取走一个数据), 

将写sudog中的元素拷贝到读index指向的位置, 读index++  环形处理, 唤醒写等待goroutine

(有一个略了, 在===中)

> 为什么这里不直接从写等待goroutine中取呢? 因为, channel是先进先出, buf中的一定是比写等待的goroutine想写入的数据早的



case2: 1不符合, buf有数据

recvx指向的元素复制到ep指针中

清空recvx指向的位置, 置为默认值即可

recvx++ 环形处理, qcount-- 解锁



case3: 12都不符合, 阻塞逻辑

创建一个sudog, 初始化各种数据, 放入读等待recvq中, gopark从GMP移除 挂起



case4: nil

永久挂起

maingoroutine就是程序退出, 死锁错误	



case5: channel关闭了

已经关闭

若没有可读的了, 清空ep, 置0值,

若有可读的, 就你妈不讲了? 就接着读



channel关闭

nil: panic

加锁

二次关闭? panic

c.closed = 1

唤醒所有的读写goroutine









----

channel接发数据的本质: 值的拷贝  ep指针





-----





## select

没讲源码哈哈哈哈哈哈哈, 也没讲底层实现

goready gopark

其实很简单啊, 如果所有的case都无法执行, 且没有default, 那么, 其实, 就可以看作是多个channel的某个操作都无法执行, 将当前goroutine和这些channel绑定起来, 也就是一个sudog, 加入对应的channel的对应的等待队列中, 即可~

 

(截图)

1．对nil的channel进行读和写都会造成当前goroutine永久阻塞（(如果当前
goroutine是main goroutine，则会让整个程序直接报fatal error 退出)，关闭则会发生panic(但这里我们不要忘记，还有一种叫做非阻塞的方式操作channel,这种模式下，就算对为nil的channel读写，也不会阻塞的)





# context

[Go标准库Context | 李文周的博客 (liwenzhou.com)](https://www.liwenzhou.com/posts/Go/context/)

context.Context是一个接口  规定了四个函数 其实这四个函数, 目前来看是很简单清晰的, Deadline就是返回一个时间而已, Done返回一个channel, 只有在context被关闭的时候才会返回, 且是只读的.(其实这里被关闭的原因就有很多种可能了, 比如cancel被调用, 时间到了, 或者父context被关闭, 父被关闭又有多种可能, 比如cancel被调用, 时间到了, 或者父的父context被关闭)  Err就是返回一个关闭的原因而已 Value就是配合key value功能, 以及WithValue函数

两个生成顶层context对象的函数: Go内置两个函数：`Background()`和`TODO()`，这两个函数分别返回一个实现了`Context`接口的`background`和`todo`。我们代码中最开始都是以这两个内置的上下文对象作为最顶层的`partent context`，衍生出更多的子上下文对象。

WithCancel 返回一个带有新Done通道的父context的子context, 什么时候子context的Done通道被关闭呢? 调用返回的cancel或者父context的Done通道被关闭. 无论先发生什么情况。

WithDeadline 返回一个子context  当截止日过期时，当调用返回的cancel函数时，或者当父上下文的Done通道关闭时，返回上下文的Done通道将被关闭，以最先发生的情况为准.

WithTimeout和上面的Deadline道理一样, 格式略有不同而已

WithValue 挺简单, 但是类型这里没有看懂... 说的什么勾八

### context是什么

这里说的还挺好



### 接口说明

两个接口

### context的实现

四种实现 : emptyCtx cancelCtx timerCtx valueCtx    (实现了Context接口规定的四个方法即可, 所以这其实是四个类型)

#### emptyCtx

作为根Context, 用一系列with函数派生出新的Context

background TODO方法返回一个实现了Context接口的对象emptyCtx, 一般用于顶层context使用(context树的根节点)

看文档吧, 很简单, `type emptyCtx int`

几个数据成员, Done方法没看懂, 但是核心是返回的这个channel是只读的, 所以只有在关闭这个channel的时候会读到零值, 一般会搭配select的非阻塞读取(多次调用Done返回的chan是同一个) cancel方法

#### cancelCtx

cancelCtx : WithCancel返回的context实现对象实际上就是这个类型的对象

结构体一个锁, 一个channel 一个map 一个error

Done方法的具体实现(Context接口规定的方法之一)   cancel方法

====   看文档吧

channel只读, cancel取消一个cancelCtx时, 不仅会遍历取消所有子context, 还会从父context中的map中移除这个context

![image-20240109135212752](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\context.assets\image-20240109135212752.png)

取消左侧红色, 右边的三个都会被取消, 同时第一个WithCancel的map中不会存储这个WithCancel

---

cancelCtx如何获取?  WithCancel

看源码, 很清晰, 所以, WithCancel返回的这个取消函数, 其实就是cancelCtx的cancel方法

又是一段源码, 不想看 ===

> 所以其实, cancelCtx就是可以调用函数进行取消的context, 且遍历子context进行取消

#### timerCtx

timerCtx : 可以说是对于cancelCtx的一个扩展了, cancelCtx没有最终时间, 只能调用方法, 而这里还可以定过期时间

结构体, 内部一个cancelCtx, 一个Timer 一个Time

所以它拥有cancelCtx的全部功能  自己的cancel实现

WithTimeout  WithDeadline 都是返回的timerCtx

===



#### valueCtx

valueCtx : 不是用于父子context之间取消的

结构体, 一个Context, 一个kv 都是interface{}类型

它的Value方法===

![image-20240109141456060](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\context.assets\image-20240109141456060.png)

也就是说, 每次调用WithValue传入一个父context, 获取一个子的valueCtx Context, 每个valueCtx只能存储一个kv

且是有父子关系的, 其实每个With系列的函数, 都是用于创建子Context的, 都是有父子关系的

WithValue的源码, 也比较简单



# defer

> 静下心来看看文档OK的, 有时间或者有兴趣的话可以再搜搜其它文档





## defer是什么

===

## defer使用形式

===

## defer底层结构

_defer结构体 组织成一个链表 当前goroutine的\_defer指向这个链表的头结点

结构体 ===

## defer执行过程

三种, 开放编码(内联), 栈, 堆

性能由高到低, 且优先使用高性能

### 堆上分配

go 1.13之前只能在堆上分配_defer   

deferproc  ====

newdefer ===... 本地, 全局的defer缓存池

### 栈上分配

go 1.13 之后引入的 优化了性能

deferprocStack, 其实就是对传来的, 一个在栈上分配的_defer结构进行初始化

其中heap字段为false

### 开放编码(内联)

go 1.14引入的优化defer性能的方式

使得在函数末尾直接对defer函数进行调用, 减少了函数调用开销

![image-20240109154857189](C:\Users\yangzilong\Desktop\markdown\CS\Golang\原理剖析\defer.assets\image-20240109154857189.png)

===

go 1.14 之后, defer优先采用内联的方式处理defer调用, 但是有条件====

## defer函数执行

deferreturn 执行defer链表中的各个defer函数

====

---

总结: ===





# interface

> 能看懂, 但是感觉... 不够细可能, 可以再找找文档或者视频



核心: 一个接口可以被多个类型实现, 一个类型可以实现多个接口, 所以有了itabTable















interface 接口

### 空接口interface{}

空接口 eface 结构体

```Go
type eface struct {
    _type *_type
    data unsafe.Pointer
}
```

是一个结构体

### _type是什么

结构体, Golang中的所有类型的一个抽象, 包含..... 决定了data如何解释和操作

几乎所有数据结构都可以抽象为_type

结构源码===

### 非空接口

实现与空接口有所不同

```Go
type iface struct {
    tab *itab
    data unsafe.Pointer
}
```

data一样 (*int)

itab 结构 存储了 接口要求的方法列表, 以及动态类型信息

====

### itab缓存

===  还可以挺好理解  每个非空interface接口和具体类型, 就可以确定一个itab, 而不管具体类型的对象怎么变, itab不变

### itabTable

itabTable缓存所有的itab结构

结构体嘛

===

核心是一个数组(哈希表), 下标其实就是接口类型与实际类型分别哈希之后的哈希值的异或值

对应的值就是*itab, 指向itab结构体呗



# GMP

https://www.bilibili.com/video/BV19r4y1w7Nx/?spm_id_from=333.337.search-card.all.click

看完了, 快速看也可以, 只看内容不听文字也可以吧

p2 历史  p3 GMP模型简介 p4 调度器的设计策略 p5 go func()执行流程 p6 M0 G0  p9-p17 一些场景



除了最后的源码部分, 大部分和视频是匹配的, 只是有些细节不太一样, 再看看其它文章吧



# Go垃圾回收

混合写屏障没看懂, 其它的大致是懂得, 但是更深的联系可能还需要再看看其它文章

有些描述不是很严谨



## 标记清除算法

回收写冲突   todo

## 三色标记算法

为了解决标记清除的stop the world, 

白 灰 黑

白色: 起初都是白色  回收结束时, 所有白色代表不可达, 会被回收

灰色: 活跃的, 该对象不能回收, 但是存在指向白色对象的外部指针, 需要继续扫描其子对象

黑色: 活跃的, 该对象不能回收, 且所有字段都已被扫描, 不存在指向白色对象的指针



不就是一样的吗, 扫描完时, 能到的就是黑色, 到不了的就是白色, 只是说在扫描过程中, 有一个灰色状态, 灰色表示这个对象引申的对象还没有扫描, 它即将成为黑色





首先分析没有STW的三色标记法存在的问题

发生问题的两个条件

黑色引用白色 (破坏了原本的黑色的定义)

灰色到达白色的还没有扫描的路径被破坏了



12同时发生, 也就是原本的路没了, 加了一个不会扫描的路, 这个白色就被错误的回收了

或者1单独存在, 2根本没有, 也就是没有路被破坏, 而是突然加了一个不会扫描的路, 也会错误回收

总之结果一定是, 白色被黑色引用, 白色被错误回收





## 屏障技术

#### 强三色不变性, 弱三色不变性

现在就是STW会影响性能, 但是不用STW又有问题, 怎么办?

需要破坏两个条件

黑色不会指向白色

黑色可以指向白色, 只是必须由灰色可达(也就是未来还是会把这个白色变为黑色, 最终结果也是黑色不会指向白色, 只是这个指的是过程中)



如果存在强的情况下, 弱只要想发生, 就一定会出现黑创建指向白的指针, 这样如果有强, 这个白就会变为灰啊



#### 屏障技术

并发或增量标记 todo   屏障技术 保证 三色不变性   没听懂...    核心就是插入写屏障  删除写屏障

###### 插入写屏障

其实很简单, 当A引用B时, 把B变为灰(记住, 灰色是会变为黑色的), 如果一个黑引用了白, 那么白变为灰, 就可以保证强三色不不变性了



只有堆开启了插入写屏障

也就是, 堆上的黑色对象突然创建一个引用, 引用白色对象因为有插入写屏障, 所以没有问题, 而栈没有开启, 也就是可能出现黑色引用白色, 解决方法是, 开启STW, 直到栈空间的三色标记结束



###### 删除写屏障

灰引用白, 也就是还没有扫描, 那么, 删除这个引用关系时, 将被删除的标记为灰色(将来是不被删除的)

其实就是说, 被删除的一定要灰化处理, 特别针对白色的情况



优点 : 如果一个灰引用白, 这个引用被删除, 同时这个白又被其它的黑引用, 则不会出现问题, 因为引用被删除, 则这个白对象自动变为灰色

缺点: 可能某个白色确实被所有对象解除引用了, 但是还是变为了灰色, 也就是这一轮没有成功被回收, 需要到下一轮~



###### 混合写屏障









----



在Golang（Go语言）的垃圾回收（GC）机制中，"三色标记法"是一个用于追踪和回收无用内存的算法。这个算法在内存管理中非常重要，尤其是在自动垃圾回收的语言中，如Go。三色标记法的核心概念涉及将对象标记为三种颜色之一：白色、灰色、黑色。这些颜色用于表示对象的访问和处理状态。

1. **白色：** 这种颜色代表尚未被访问的对象。在算法开始时，所有对象都被标记为白色。
2. **灰色：** 这种颜色表示对象已被访问，但其引用的对象尚未全部访问。灰色对象可能还包含对其他白色对象的引用。
3. **黑色：** 这种颜色表示对象已被访问，并且所有引用的对象也都已被访问。黑色对象不会引用任何白色对象。

垃圾回收过程通常包括以下步骤：

- **初始标记：** 标记所有从根对象（如全局变量、活动线程的栈帧等）直接可达的对象。这些对象被标记为灰色。
- **标记阶段：** 在这个阶段，灰色对象被检查，并将它们引用的所有白色对象标记为灰色。一旦一个灰色对象的所有引用都被检查过，它就会变成黑色。这个过程持续进行，直到没有更多的灰色对象。
- **清扫阶段：** 在所有的对象都被检查过后（即没有灰色对象），所有仍然是白色的对象被认为是不可达的，因此可以安全地回收。

Go语言的垃圾回收器使用了三色标记法的变体，并结合了并发执行和写屏障技术，以减少垃圾回收对程序性能的影响。通过并发运行垃圾回收过程，并使用写屏障来维护对象颜色的正确性，Go的垃圾回收器既能高效地回收内存，又能最小化对程序运行的干扰。

# 逃逸分析

