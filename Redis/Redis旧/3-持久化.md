# 持久化

> MySQL事务的四大特性之一就是持久性. **把数据存储在磁盘中，就是持久。把数据存储在内存中，就是不持久。**持久和不持久的关键就在于重启进程/重启主机之后，数据是否还存在。
>
> Redis是一个内存数据库，即，把数据存储在内存中，内存中的数据是不持久的，掉电易失。要想做到持久，就需要将Redis的内存中存储的数据在硬盘上也存储一份。
>
> **所以，要想做到Redis的持久化，实现思路就是：当内存插入一个新的数据的时候，就需要将这个数据，同时写入硬盘。**（当然，这里实际上具体怎么写硬盘，还是有不同的策略的，并非只要内存中的数据一改动就立即写硬盘进行持久化，因为这样的效率就太慢了。通过合理的持久化策略，可以保证整体的效率还是足够高的。
>
> 这样一来，当查询或者修改某个数据的时候，直接从内存中读取，保证效率高。而硬盘中存储的数据只是在Redis重启的时候，用于恢复内存中的数据的，保证持久性。
>
> 这样的好处就是，做到了Redis的持久化，而代价就是消耗了更多的存储空间（硬盘空间，同一份数据存储两份），并且写硬盘也会消耗一些时间，也就是空间+时间的代价。不过，硬盘比较便宜，所以空间代价几乎可以忽略，而合理的持久化策略会使得时间代价也在可以接受的范围之内。

**Redis ⽀持 RDB 和 AOF 两种持久化机制，持久化功能有效地避免因Redis服务端进程退出造成内存中的数据丢失问题，当下次重启时利用之前持久化的文件即可实现数据恢复（恢复内存中的数据）。**

**可以将RDB理解为定期备份**，也就是每隔若干时间，将内存中的数据备份一份到硬盘中。

**可以将AOF理解为实时备份**，也就是只要内存中的数据发生了修改，就"立即"把这个数据备份一份到硬盘中。

## RDB

---

前言: 看完了redis设计与实现的关于RDB的这一节... 

其实很简单啊, save就是服务器阻塞生成rdb文件, bgsave就是服务器创建子进程来生成rdb文件, 所以bdsave不会影响redis服务器去处理其他客户端的命令请求.

然后就是可以通过save配置选项来指定rdb每隔多久/每发生多少次修改, 就执行一次bgsave. 实现上来说就是: redis服务器struct中记录save配置, 并且记录距离上次save/bgsave的修改次数/时间, 然后周期性的来判断是否有某个save配置项达成了要求. 若有就执行bgsave呗, 就这么简单啊...

我下面写的这个, 逻辑混乱, 内容排版混乱... 用来了解了解周边细节倒是还不错....

---



RDB - Redis DataBase

**RDB机制即Redis定期的把Redis内存中的数据生成一个rdb文件，写入硬盘中。后续当Redis服务器重启了，内存数据没了，就可以根据之前的RDB"快照"文件将内存中的数据恢复出来。**

**RDB持久化是把当前进程数据生成快照文件保存到硬盘的过程，触发 RDB 持久化过程分为手动触发和自动触发。**

**上方所说的RDB“定期”持久化，主要指的是自动触发，也就是通过配置文件中的save配置的方式。**

### RDB触发机制

#### 手动触发

手动触发RDB分别对应save和bgsave命令，就是程序员通过redis客户端执行命令，来触发Redis服务端进行RDB快照文件的生成。

- **save 命令：阻塞当前 Redis 服务器**，直到 RDB 过程完成为⽌**，对于内存比较大的实例造成长时间阻塞，基本不采用。**（Redis单线程模型，也就是服务端执行save生成快照文件的过程中无法处理其他客户端的请求，导致类似于keys *的效果）
- bgsave 命令：bg -> background，**Redis 服务端进程执行 fork 操作创建子进程，RDB 持久化过程由子进程负责。**阻塞只发⽣在 fork 阶段，⼀般时间很短。所以不会影响Redis服务器处理其他客户端的请求和命令。
  （注意，这里采用的是多进程并发编程实现bgsave，而不是多线程）

##### bgsave的执行流程

<img src="https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904143428622.png" alt="image-20230904143428622" style="zoom: 67%;" />

1. redis服务端执⾏ bgsave 命令，Redis ⽗进程判断当前进程是否存在其他正在执⾏的⼦进程，如 RDB/AOF ⼦进程，如果存在，bgsave 命令直接返回。
2. **⽗进程执行 fork 创建⼦进程**，fork 过程中⽗进程会阻塞
   (通过 info stats 命令查看 latest_fork_usec 选项，可以获取最近⼀次 fork 操作的耗时，单位为微秒。)
3. ⽗进程 fork 完成后，bgsave 命令返回 "Background saving started" 信息，并不再阻塞⽗进程，可以继续响应其他命令。
4. **⼦进程创建 RDB ⽂件，根据父进程内存生成临时快照文件，完成后对原有rdb文件进行原子替换。**
   (执⾏ lastsave 命令可以获取最后⼀次⽣成 RDB 的时间，对应 info 统计的 rdb_last_save_time 选项。)
5. **子进程发送信号给⽗进程表示完成**，⽗进程更新统计信息。

#### 自动触发

除了⼿动触发之外，Redis 支持⾃动触发 RDB 持久化机制，**自动触发机制才是在实战中有价值的。**

> rdb文件的存储路径，文件名，rdb文件会压缩，rdb文件的校验方式等。
>
> **RDB文件的保存**：RDB ⽂件保存在redis的配置文件中的 dir 配置指定的⽬录（默认 /var/lib/redis/）下，⽂件名通过 dbfilename 配置（默认 dump.rdb）指定。
>
> <img src="https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20231124163058059.png" alt="image-20231124163058059" style="zoom: 50%;" />
>
> ![image-20230904134940537](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904134940537.png)
>
> **RDB文件的压缩**：**把内存中的数据，以压缩的方式保存在这个二进制文件中。**Redis 默认采⽤ LZF 算法对⽣成的 RDB ⽂件做压缩处理，**压缩后的⽂件远远小于内存大小**，默认开启，可以通过参数 config set rdbcompression {yes|no} 动态修改。
>
> **虽然压缩 RDB 文件会消耗 CPU，但可以⼤幅降低生成的⽂件的体积，⽅便保存到硬盘或通过⽹络发送给从节点，因此建议开启。**
>
> ![image-20230904131556444](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904131556444.png)
>
> **RDB文件的校验**：如果 Redis 启动时加载到损坏的 RDB ⽂件会拒绝启动。这时可以使⽤ Redis 提供的 redis-check-dump ⼯具检测 RDB ⽂件并获取对应的错误报告。
>
> ![image-20230904134841159](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904134841159.png)
>
> 上图所示的dump.rdb文件即RDB持久化生成的二进制快照文件
>
> 当进行RDB持久化生成快照文件时，会先把要生成的快照数据保存在一个临时文件中，当这个快照生成完毕之后，再删除之前的rdb文件，把新生成的快照文件文件名改为之前的dump.rdb。所以，rdb持久化操作可以进行多次，但是始终只会有一个rdb文件存在（不是同一个）

##### 自动触发机制的配置

<img src="https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904141602629.png" alt="image-20230904141602629" style="zoom:80%;" />

Will save the DB if both the given number of seconds and the given number of write operations against the DB occurred：将保存这个数据库如果给定的秒数和给定的对数据库的写操作的次数都足够时。也就是900秒内有一次写，会触发自动rdb持久化，300秒内10次写将触发自动持久化，60秒内10000次写将触发自动持久化。

虽然上方的自动持久化机制是自由配置的，但是**有一个基本的原则：生成一次rdb快照是一个成本较高的操作，不能让此操作发生的频率过高。**

**也正是因为rdb生成的不是很频繁**（如上方所示，最短的两次rdb文件的生成也是相差了60s，并且要保证这60s进行了10000次写操作才会发生），**这就导致，rdb快照文件中的数据和redis服务器内存中的实时数据可能会存在较大的偏差。而AOF就是解决这个问题，弥补RDB不足的有效方案。**

> 再补充一下，对于RDB的自动触发持久化机制，并非只有配置文件中的save配置的条件达到时会触发，还有其他情况，综合来说：
>
> 1. 使⽤ save 配置。如 "save m n" 表⽰ m 秒内数据集发⽣了 n 次修改，**⾃动 RDB 持久化。**
> 2. redis进行主从复制时，从节点进⾏全量复制操作时，**主节点⾃动进⾏ RDB 持久化**，随后将生成的RDB快照⽂件内容发送给从结点。（这时候，rdb文件的压缩就可以减少网络传输rdb文件的压力）（见Redis的主从复制）
> 3. 执⾏ shutdown / service redis-server restart 命令**正常关闭 Redis服务器 时**，**执⾏ RDB 持久化。**
>
> 手动触发的两个命令对应的持久化过程是不一样的，bgsave的多进程并发持久化是当前redis主流的rdb持久化方案，而自动触发时，其实就是redis服务器自动执行一个bgsave的过程。

### RDB的优缺点

优点

- RDB 是⼀个紧凑压缩的⼆进制⽂件，代表 Redis 在某个时间点上的内存数据快照。⾮常适⽤于全量备份，全量复制的场景。
  ⽐如每 6 ⼩时执⾏ bgsave 备份，并把 RDB ⽂件复制到远程机器或者⽂件系统中 （如 hdfs）⽤于灾备。
- **Redis 加载 RDB文件（dump.rdb） 恢复数据远远快于 AOF 的⽅式。**：RDB文件，使用二进制方式来组织数据，AOF使用文本的方式组织数据。

缺点

- **RDB ⽅式数据没办法做到实时持久化 / 秒级持久化。**因为 bgsave 每次运⾏都要执⾏ fork 创建⼦进程，形成整个内存中的数据的快照文件，还要压缩。属于**重量级操作，频繁执行成本过高。**
- > RDB ⽂件使⽤特定⼆进制格式保存，Redis 版本演进过程中有多个 RDB 版本，兼容性可能有⻛险。

### RDB实践+补充

- 插入新的key，不手动执行bgsave（此时也不会触发自动rdb）。然后直接以异常方式终止redis服务进程（比如kill -9或者直接让服务器掉电），再重启redis服务器，再get key发现确实没有。也就是这个新的key并没有及时的通过rdb进行持久化。
- 注意，如果是正常流程终止redis服务器，在redis服务器终止时会自动触发rdb操作（shutdown或者service redis-server restart）
  - 客户端bgsave，服务端触发rdb持久化。通过stat命令查看前后的dump.rdb文件，发现inode变了，说明bgsave的操作流程确实是先创建子进程，子进程进行持久化，子进程会先生成临时的rdb文件，然后用新文件替代旧文件。
    ![image-20230904151839475](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904151839475.png)

- 手动修改rdb文件（不建议这样，除非疯了，现在目的是测试），然后重启redis服务，因为redis服务在启动时会读取rdb文件以恢复内存中的数据（持久化），而错误的rdb文件会让redis服务启动失败（结果不可预期，也不一定会启动失败）。（实践过了，确实失败了，把对dump.rdb文件的修改该回去，再重启，又成功了。）
  此时，也可以通过看redis的日志文件，了解一下发生了什么`/var/log/redis/redis-server.log`
  ![image-20230904153022127](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904153022127.png)
  同时，redis-check-rdb可以用来检查rdb文件的状态

---

上面有很多细节, 不过重点其实很少, bgsave的执行流程, save bgsave的区别, 自动进行RDB持久化的配置方式, bgsave是一个重量级操作, 这也是RDB的缺点, 适用于定期的全量备份, 无法做到实时备份, 所以引出AOF

## AOF

**AOF持久化机制**

AOF（Append Only File）持久化：以独⽴⽇志的⽅式**记录每次写命令（文本的方式，其实就是客户端传来的命令），重启时再重新执行 AOF 文件中的命令达到恢复数据的目的。AOF 的主要作用是解决了数据持久化的实时性，⽬前已经是 Redis 持久化的主流⽅式。**理解掌握好 AOF 持久化机制对我们兼顾数据安全性和性能⾮常有帮助。

和rdb一样，同样是通过配置文件可以开启/关闭aof功能，并指定生成的aof文件的文件名。所在的位置也是在redis的工作目录下。
![image-20230904162544443](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904162544443.png)

当开启aof时，rdb就不生效了，redis服务启动时，就不会再读取rdb文件内容了。

### AOF工作流程

![image-20230904182245299](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904182245299.png)

AOF 的⼯作流程操作：

- 命令写⼊（append）：**所有的写操作命令会以Redis的协议格式写入到内存缓冲区中（aof_buf）中**
- ⽂件同步（sync）：**当刷新条件达成时，将aof_buf缓冲区中的数据同步刷新到硬盘的aof文件中。**
- ⽂件重写 （rewrite）：bgrewriteaof，可手动，可自动。
- 重启加载（load）：redis服务器启动时，加载aof文件进行数据恢复。

AOF 过程中为什么需要 `aof_buf` 这个缓冲区？

Redis 使⽤单线程响应命令，如果每次命令都直接同步硬盘，性能从内存的读写变成 IO 读写，性能必然会大幅下降。先写⼊缓冲区再定期同步刷新磁盘可以有效减少 IO 次数，**同时，Redis 还可以提供多种缓冲区同步策略**，让⽤⼾根据⾃⼰的需求做出合理的平衡。

> **此处内容用于理解aof_buf缓冲区的作用还有AOF的机制**
>
> 但是，问题是，redis是一个单线程模型服务，速度快，重要原因就是因为只操作内存。引入AOF持久化机制之后，每次写操作，又要写内存，又要写硬盘，这样效率如何保证呢？
>
> **答：**
>
> 1. **AOF机制并非是让工作线程在每次发生写操作时都将写操作的文本格式写入硬盘，而是在内存中维护一个缓冲区，先将写操作放入内存缓冲区中，等待时机成熟，再统一写入硬盘。**
>    这样一来，大大降低了写硬盘的次数！之前也说过，写硬盘的数据多少不是影响效率的主要因素，而是写硬盘的次数！
>
> 2. 硬盘上读写数据时，顺序读写的速度大于随机访问读写的速度。AOF是每次将新的操作写入到原有文件的末尾，属于顺序读写。
>
> 那么，缓冲区还是在内存中啊，进程异常退出，这个数据还是没了，那么，缓冲区中的没来得及写入硬盘的数据还是会丢失。
>
> 所以，内存中的AOF缓冲区什么时候刷新到磁盘中就很重要了。简单来说：刷新越频繁，redis的数据的实时持久化越好，但是性能越低（对性能影响越大）。刷新越不频繁，redis数据实时持久化越差，但是性能越好（影响越小）
> （这里和MySQL的事务的隔离级别很像，隔离级别越高，隔离性越好，但是并发效率越低。而隔离级别越低，隔离性越差，并发效率越好。）
>
> 而在redis的配置文件中就有刷新策略的配置。

---

### 缓冲区aof_buf同步文件策略

**其实就是AOF工作流程中的第二步，而具体来说，第二步又可以分为两步: **

1. 将aof_buf缓冲区中的数据写入到AOF文件中（AOF文件在OS内核中的文件缓冲区, 此时并没有真正持久化）
2. 将AOF文件的内存缓冲区中的数据同步到磁盘的AOF文件中（真正的持久化到磁盘中了）。

而具体来说，这里的策略实际上是第2步的执行策略不同，因为第二步的策略才真正决定AOF的效率。

![image-20230907152845739](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230907152845739.png)

Redis 提供了多种 AOF 缓冲区同步⽂件策略，由参数 appendfsync 控制

![image-20230904165036386](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904165036386.png)

![image-20230904165056923](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904165056923.png)

![image-20230907152809074](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230907152809074.png)

![image-20230907152903716](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230907152903716.png)

![image-20230907152920238](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230907152920238.png)

系统调⽤ write 和 fsync 说明：

- write 操作会触发延迟写（delayed write）机制。Linux 在内核提供页缓冲区⽤来提高硬盘 IO 性能。write 操作在写⼊系统缓冲区后⽴即返回。同步硬盘操作依赖于系统调度机制，例如：缓冲区页空间写满或达到特定时间周期。同步⽂件之前，如果此时系统故障宕机，缓冲区内数据将丢失。
  简单来说，不管是always everysec no，每次都会调用write将aof_buf中的数据写入到文件中（OS内核缓冲区）。对于Fsync进行同步文件的策略是不同的。
- Fsync 针对单个⽂件操作，做强制硬盘同步，**fsync 将阻塞直到数据写⼊到硬盘。**
- **配置为 always 时，每次写入都要同步 AOF ⽂件，性能很差**，除⾮是⾮常重要的数据，否则不建议配置。
- 配置为 no 时，由于操作系统同步策略不可控，虽然提⾼了性能，但数据丢失⻛险⼤增，除⾮数据重要程度很低，⼀般不建议配置。
- 配置为 everysec，是默认配置，也是推荐配置，兼顾了数据安全性和性能。理论上最多丢失1 秒的数据。

### AOF的重写机制

#### AOF重写机制解决的问题

> AOF文件以文本格式保存每次写操作命令，那么，**AOF文件随着写操作越来越多，体积越来越大**。
>
> 导致以下问题
>
> 1. **体积越来越大占用存储空间**，如果体积过大的AOF文件可能会对redis服务器甚至计算机造成影响。
> 2. **使用AOF文件进行数据还原所需时间越来越多。**（并且aof文件中记录的是所有写操作的过程，也就一定存在冗余。但是事实上redis服务启动时只关注上一次redis终止前，内存中的最终结果）
>
> 这个问题怎么解决？
>
> 因此，**AOF的重写机制就是用来解决这个问题的。**

1. **较小的 AOF 文件一方面降低了硬盘空间占用**
2. **可以提升启动 Redis 时数据恢复的速度。**

AOF 重写机制分为⼿动触发和⾃动触发：

- **⼿动触发：**调⽤ bgrewriteaof 命令。

- **⾃动触发：**根据 auto-aof-rewrite-min-size 和 auto-aof-rewrite-percentage 参数确定⾃动触发时机。 
  
  > auto-aof-rewrite-min-size：表⽰触发重写时 AOF 的最⼩⽂件⼤⼩，默认为 64MB。
  >
  > auto-aof-rewrite-percentage：代表当前 AOF 占⽤⼤⼩相⽐较上次重写时增加的⽐例。

总之，重写的核心还是bgrewriteaof的执行。

#### AOF重写的流程

![image-20230904170055937](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904170055937.png)

bgrewriteaof  - bg rewrite aof

- 父进程执行 fork 创建子进程。

- 重写

  3.1）：主进程 fork 之后，继续响应其他客户端的命令。期间的所有修改操作继续写⼊内存中的 aof_buf 缓冲区并根据 appendfsync 策略同步到硬盘，保证旧 AOF ⽂件机制正常执行。

  3.2）：因为⼦进程只有 fork 之前的所有内存信息，所以，⽗进程需要将 fork 之后这段时间的写修改操作写⼊一个名为aof_rewrite_buf 的缓冲区中。否则，最终重写生成的新aof文件中只有fork之前的内存数据，fork之后的，重写期间的内存数据将丢失。**这里是比较关键的，因为RDB并不会进行这样的行为**
  
  4）：⼦进程根据内存中的键值对数据，以命令文本的格式写入到一个新的AOF文件中。
  
  > 注意，4的最终目的是为了保存内存中的数据，所以，这里并不是对旧的AOF文件中的文本数据进行去冗余。而是直接将内存中的数据，以AOF的格式写入到这个新的AOF文件中。
  >
  > ![image-20231124181341142](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20231124181341142.png)
  >
  > 这是一个例子
  >
  > ![image-20230907163636576](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230907163636576.png)
  
- ⼦进程完成重写，新AOF文件写⼊完成，⼦进程发送信号给⽗进程。（5.1）⽗进程收到信号会调用一个信号处理函数：把 aof_rewrite_buf AOF重写缓冲区内保存的命令追加到新 AOF ⽂件中。这时新AOF文件所保存的数据库状态将和服务器当前的数据库状态一致（5.2）⽤新 AOF ⽂件替换⽼ AOF ⽂件。（原子的atomic）（5.3）

- bgrewriteaof重写完成

![image-20230907163532934](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230907163532934.png)

---

补充

- bgrewriteaof命令执行的可能情况

  - 如果在执行bgrewriteaof时，当前redis又收到了新bgrewriteaof请求，会直接返回（不处理该请求）

  - 如果在执行bgsave时（生成rdb快照文件），当前redis收到了bgrewriteaof请求（重写aof文件），则重写操作会等待rdb快照生成完毕，再进行aof文件重写。


- 对比bgsave和bgrewriteaof的过程会发现：rdb对于fork创建子进程之后收到的新的数据，就置之不理了，也就是子进程生成的rdb文件只包含fork之前的内存数据。而aof的父进程fork之后，对于新数据会写入到aof_rewrite_buf中，最终再合并到子进程重写的新AOF文件中。  这样的区别怎么理解？
  
  这和rdb，aof的设计理念有关。**RDB本身就是定期备份**，定期备份这个思想本身就允许了备份数据和实时内存数据存在偏差，因为它是定期才会进行一次。而AOF本身就是实时备份的思想，所以为了保证备份数据的实时性，就处理了fork之后的新数据~


- bgrewriteaof中的3.1步骤有必要吗？子进程重写完新AOF文件，信号通知父进程，父进程补充一下aof_rewrite_buf中的数据，就会用新AOF文件替代旧的AOF文件。为什么还要3.1？
  父进程写这个即将消亡的旧AOF文件是否有意义？
  
  答 : 考虑极端情况，重写过程正在执行，服务器挂了，此时aof_rewrite_buf是在内存中的，也就丢失了，并且子进程重写的新AOF文件的完整性还不能保证，因此如果不坚持写旧AOF文件，若此情况发生，则redis服务重启就没法保证数据完整性。


- Redis的工作目录中既有aof文件又有rdb文件，以谁为准？

  以AOF为准，RDB直接忽略。原因很简单：AOF是实时备份, 备份数据比RDB更完整.

  <img src="https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904180551219.png" alt="image-20230904180551219" style="zoom:67%;" />


### 混合持久化

redis.conf appendonly yes打开aof，重启redis服务，发现/var/lib/redis/下确实就有了appendonly.aof文件（同时有rdb文件，但是不用）

![image-20230904175718446](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904175718446.png)

上面这个配置选项为混合持久化功能是否开启。

因为AOF的机制为将写操作按照文本的方式写入文件中，但是，**redis服务重启时加载文本文件并恢复数据是比加载二进制的RDB文件慢的（aof对比rdb的一个缺点）**
所以，混合持久化的策略就是：在bgrewriteaof逻辑中，子进程在重写生成新的AOF文件时，会把当前内存中的数据按照rdb的二进制格式写入到新的aof文件中。重写完成后，后续的新的写操作，依旧是按照aof的文本格式追加到aof文件后方. 也就是, 你会发现aof文件中既有RDB的二进制格式数据，又有AOF的文本格式数据

但是，（3.2的过程是以RDB的二进制格式还是AOF的文本格式是不确定的，不过也不是很重要说实话，有待考证。不过二进制肯定是比文本更快的，预测是RDB的二进制。因为混合持久化本身就是为了提高这个效率呀~

![image-20230904180335858](https://cdn.jsdelivr.net/gh/DaysOfExperience/blogImage@main/img/image-20230904180335858.png)

如上图所示，即先bgrewriteaof重写aof文件（打开混合持久化），再新set一些key，就会有上图情况。

---

## AOF vs RDB

1. Redis 提供了两种持久化⽅案：RDB 和 AOF。
2. RDB 视为内存的快照，生成的备份文件占⽤空间较小，恢复时速度更快。但产⽣ RDB 的开销较⼤，不适合进⾏实时持久化，⼀般⽤于全量备份, 冷备和主从复制。
3. AOF 视为对修改命令保存，在恢复时需要重放命令。并且有重写机制来定期压缩 AOF ⽂件。同时为了避免每次写操作都写硬盘导致效率降低，设定了不同的同步策略。
4. RDB 和 AOF 都使⽤ fork 创建⼦进程，利⽤ Linux ⼦进程拥有⽗进程内存快照的特点进⾏持久化， 尽可能不影响主进程继续处理后续命令。
5. aof是一个文本文件，记录每次的写操作，也因此，加载aof文件恢复数据的速度远小于加载rdb二进制文件恢复数据的速度。

## 总结

AOF：有文件同步策略，从aof_buf 调用write写入到aof文件的内存缓冲区中之后，再按照不同的同步策略(always，everysec，no)通过fsync方法同步到磁盘的aof文件中。（文件写入与文件同步)

为了解决AOF文件无限增大的问题，有了AOF重写机制，主要是bgrewriteaof方法，可直接调用，也有配置策略，也就是多久进行自动的重写一次。

AOF重写主要是三个过程，不是很难，主要是创建子进程的方式，因为不想阻塞redis服务端处理其他客户端的请求。看图即可。剩下的细节就不说了比如aof重写并不对原先的aof文件做处理而是直接读取内存中的键值对数据。上面也写的很清楚了。



RDB：save，bgsave，一个阻塞redis服务器，一个不阻塞redis服务器（多进程）。save基本不考虑了。

bgsave的过程也很简单，就是创建一个子进程让子进程去根据内存数据生成rdb文件。重量级操作，所以只能定期进行。

手动就不说了其实就是两个指令可以直接执行。

针对定期执行，有save配置可以指定定期rdb持久化的策略。所以也没什么....
